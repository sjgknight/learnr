<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Simon Knight, sjgknight@gmail.com, modified by Shibani Antonette, antonette.shibani@gmail.com, and converted to a learnr exercise in 2021 by sjgk" />

<meta name="date" content="2022-08-23" />

<meta name="progressive" content="true" />
<meta name="allow-skip" content="true" />
<meta name="learnr-version-prerender" content="0.10.2" />

<title>Match the code snippet to questions on data!</title>

<!-- header-includes START -->
<!-- HEAD_CONTENT -->
<!-- header-includes END -->
<!-- HEAD_CONTENT -->

<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>


<!-- taken from https://github.com/rstudio/rmarkdown/blob/de8a9c38618903627ca509f5401d50a0876079f7/inst/rmd/h/default.html#L293-L343 -->
<!-- tabsets -->
<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>
<!-- end tabsets -->


</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<div id="section-match-the-code-to-the-question" class="section level2">
<h2>Match the code to the question</h2>
<p>In this notebook, we’ve got a set of questions.</p>
<p><strong>Your challenge is to match the question, to the appropriate
code chunk(s). For charts you <em>don’t</em> use, can you explain why
not/what’s wrong with them?</strong></p>
<p>Try and work out what the code chunk will output before you run
it.</p>
<p>The code snippets are designed so you could copy them into your own
work to do analyses (if you wanted to), and to demonstrate useful
functions.</p>
<div id="section-preliminaries" class="section level3">
<h3>Preliminaries</h3>
<p>This chunk (which is hidden) loads some libraries and data.</p>
<p>If you’re running this in ‘interactive’ mode, you don’t need to do
anything. If you’re not, you might need to install the libraries by
uncommenting (delete the #) the first line in the following code block
(starting ‘install.packages’)</p>
<p>Once you’ve done that, you can test the file by using the ‘knit’
button (in RStudio).</p>
<p>Read more about R markdown and ‘kniting’ (rendering) documents <a
href="https://rmarkdown.rstudio.com/authoring_quick_tour.html#overview"
class="uri">https://rmarkdown.rstudio.com/authoring_quick_tour.html#overview</a></p>
<p>To read documentation and view examples of usage, type ?function_name
in console (E.g. ?hist) or search from the help bar in RStudio.</p>
<p>First, we’ll load the required packages, they come with a bunch of
built in data, and we’re going to use that here.</p>
</div>
</div>
<div id="section-task-explanation" class="section level2">
<h2>Task Explanation</h2>
<p>We’re going to look at the trump twitter data</p>
<p>I’ve put some questions below - what other questions can you think of
from this dataset?</p>
<p>In some of the examples below, it’s not about “right” and “wrong”
answers, so much as “more” and “less” informative ones. In other cases,
there is a clear wrong answer :-). In both, we can discuss this!</p>
<div id="section-data-exploration" class="section level3">
<h3>Data Exploration</h3>
<p>First, let’s just look at the first 10 rows of the dataset to see
what it includes. You can change the below to
<code>tail(trump_tweets)</code> or <code>trump_tweets[1:100,]</code>,
etc. Use the arrow in the top row to navigate through the columns.</p>
<div class="tutorial-exercise" data-label="explore-datasets"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="2">
<pre class="text"><code>#View the first 10 rows of the dataset
head(trump_tweets)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["source"],"name":[1],"type":["chr"],"align":["left"]},{"label":["id_str"],"name":[2],"type":["chr"],"align":["left"]},{"label":["text"],"name":[3],"type":["chr"],"align":["left"]},{"label":["created_at"],"name":[4],"type":["dttm"],"align":["right"]},{"label":["retweet_count"],"name":[5],"type":["int"],"align":["right"]},{"label":["in_reply_to_user_id_str"],"name":[6],"type":["chr"],"align":["left"]},{"label":["favorite_count"],"name":[7],"type":["int"],"align":["right"]},{"label":["is_retweet"],"name":[8],"type":["lgl"],"align":["right"]},{"label":["sent_split"],"name":[9],"type":["list"],"align":["right"]},{"label":["element_id"],"name":[10],"type":["int"],"align":["right"]},{"label":["word_count"],"name":[11],"type":["int"],"align":["right"]},{"label":["sd"],"name":[12],"type":["dbl"],"align":["right"]},{"label":["ave_sentiment"],"name":[13],"type":["dbl"],"align":["right"]},{"label":["polarity"],"name":[14],"type":["chr"],"align":["left"]},{"label":["sentiment_afinn"],"name":[15],"type":["dbl"],"align":["right"]},{"label":["sentiment_nrc"],"name":[16],"type":["chr"],"align":["left"]}],"data":[{"1":"Twitter Web Client","2":"6971079756","3":"From Donald Trump: Wishing everyone a wonderful holiday & a happy, healthy, prosperous New Year. Let’s think like champions in 2010!","4":"2009-12-23 12:38:18","5":"28","6":"NA","7":"12","8":"FALSE","9":"<chr [2]>","10":"1","11":"20","12":"0.8572683","13":"0.8103044","14":"Positive","15":"2.6","16":"positive","_rn_":"1"},{"1":"Twitter Web Client","2":"6312794445","3":"Trump International Tower in Chicago ranked 6th tallest building in world by Council on Tall Buildings & Urban Habitat http://bit.ly/sqvQq","4":"2009-12-03 14:39:09","5":"33","6":"NA","7":"6","8":"FALSE","9":"<chr [1]>","10":"2","11":"22","12":"NA","13":"0.2984810","14":"Positive","15":"NA","16":"positive","_rn_":"2"},{"1":"Twitter Web Client","2":"6090839867","3":"Wishing you and yours a very Happy and Bountiful Thanksgiving!","4":"2009-11-26 14:55:38","5":"13","6":"NA","7":"11","8":"FALSE","9":"<chr [1]>","10":"3","11":"10","12":"NA","13":"1.4198627","14":"Positive","15":"2.0","16":"joy","_rn_":"3"},{"1":"Twitter Web Client","2":"5775731054","3":"Donald Trump Partners with TV1 on New Reality Series Entitled, Omarosa's Ultimate Merger: http://tinyurl.com/yk5m3lc","4":"2009-11-16 16:06:10","5":"5","6":"NA","7":"3","8":"FALSE","9":"<chr [1]>","10":"4","11":"19","12":"NA","13":"0.1032371","14":"Negative","15":"1.0","16":"anticipation","_rn_":"4"},{"1":"Twitter Web Client","2":"5364614040","3":"--Work has begun, ahead of schedule, to build the greatest golf course in history: Trump International – Scotland.","4":"2009-11-02 09:57:56","5":"7","6":"NA","7":"6","8":"FALSE","9":"<chr [1]>","10":"5","11":"17","12":"NA","13":"0.3759302","14":"Positive","15":"NA","16":"positive","_rn_":"5"},{"1":"Twitter Web Client","2":"5203117820","3":"--From Donald Trump: \"Ivanka and Jared’s wedding was spectacular, and they make a beautiful couple. I’m a very proud father.\"","4":"2009-10-27 10:31:48","5":"4","6":"NA","7":"5","8":"FALSE","9":"<chr [2]>","10":"6","11":"22","12":"0.1333852","13":"0.4568176","14":"Positive","15":"2.5","16":"anticipation","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-demonstrating-a-table-data-overview"
class="section level3">
<h3>Demonstrating a Table / Data Overview</h3>
<p>Let’s just take a look at some overall summary stats before we get
into the visualisation. These are useful for a range of reasons, one of
which is they can tell us about the shape of the data. Read about a part
of that through measures of skew and kurtosis here: <a
href="https://codeburst.io/2-important-statistics-terms-you-need-to-know-in-data-science-skewness-and-kurtosis-388fef94eeaa"
class="uri">https://codeburst.io/2-important-statistics-terms-you-need-to-know-in-data-science-skewness-and-kurtosis-388fef94eeaa</a></p>
<pre class="r"><code>trump_tweets %&gt;% 
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)) %&gt;% 
  select(c(favorite_count,retweet_count,source)) %&gt;%
  psych::describeBy(favorite_count + retweet_count ~ source, data = ., mat = T) %&gt;%
  kable(.,&quot;html&quot;)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
item
</th>
<th style="text-align:left;">
group1
</th>
<th style="text-align:right;">
vars
</th>
<th style="text-align:right;">
n
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
median
</th>
<th style="text-align:right;">
trimmed
</th>
<th style="text-align:right;">
mad
</th>
<th style="text-align:right;">
min
</th>
<th style="text-align:right;">
max
</th>
<th style="text-align:right;">
range
</th>
<th style="text-align:right;">
skew
</th>
<th style="text-align:right;">
kurtosis
</th>
<th style="text-align:right;">
se
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
favorite_count1
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
TweetDeck
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
468
</td>
<td style="text-align:right;">
127.2564
</td>
<td style="text-align:right;">
1109.3851
</td>
<td style="text-align:right;">
15.0
</td>
<td style="text-align:right;">
19.92819
</td>
<td style="text-align:right;">
13.3434
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
19353
</td>
<td style="text-align:right;">
19353
</td>
<td style="text-align:right;">
14.969131
</td>
<td style="text-align:right;">
235.36598
</td>
<td style="text-align:right;">
51.28135
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count2
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
Twitter for Android
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4652
</td>
<td style="text-align:right;">
15652.4177
</td>
<td style="text-align:right;">
35565.8952
</td>
<td style="text-align:right;">
1099.5
</td>
<td style="text-align:right;">
6815.67867
</td>
<td style="text-align:right;">
1628.6361
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
633253
</td>
<td style="text-align:right;">
633253
</td>
<td style="text-align:right;">
5.004130
</td>
<td style="text-align:right;">
45.77662
</td>
<td style="text-align:right;">
521.45146
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count3
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:left;">
Twitter for iPhone
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3962
</td>
<td style="text-align:right;">
46385.5091
</td>
<td style="text-align:right;">
43431.4114
</td>
<td style="text-align:right;">
30568.5
</td>
<td style="text-align:right;">
40496.12429
</td>
<td style="text-align:right;">
36774.4104
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
605098
</td>
<td style="text-align:right;">
605094
</td>
<td style="text-align:right;">
1.710604
</td>
<td style="text-align:right;">
8.50099
</td>
<td style="text-align:right;">
689.99621
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count4
</td>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
Twitter Web Client
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
10718
</td>
<td style="text-align:right;">
1273.4445
</td>
<td style="text-align:right;">
9523.8757
</td>
<td style="text-align:right;">
39.0
</td>
<td style="text-align:right;">
104.65590
</td>
<td style="text-align:right;">
54.8562
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
616217
</td>
<td style="text-align:right;">
616217
</td>
<td style="text-align:right;">
31.300401
</td>
<td style="text-align:right;">
1709.81349
</td>
<td style="text-align:right;">
91.99344
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count1
</td>
<td style="text-align:left;">
5
</td>
<td style="text-align:left;">
TweetDeck
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
468
</td>
<td style="text-align:right;">
232.0513
</td>
<td style="text-align:right;">
725.7701
</td>
<td style="text-align:right;">
123.0
</td>
<td style="text-align:right;">
147.37766
</td>
<td style="text-align:right;">
129.7275
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
11353
</td>
<td style="text-align:right;">
11349
</td>
<td style="text-align:right;">
12.588798
</td>
<td style="text-align:right;">
174.29386
</td>
<td style="text-align:right;">
33.54873
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count2
</td>
<td style="text-align:left;">
6
</td>
<td style="text-align:left;">
Twitter for Android
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4652
</td>
<td style="text-align:right;">
4595.0714
</td>
<td style="text-align:right;">
10544.3325
</td>
<td style="text-align:right;">
772.0
</td>
<td style="text-align:right;">
2397.20688
</td>
<td style="text-align:right;">
1140.1194
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
344806
</td>
<td style="text-align:right;">
344806
</td>
<td style="text-align:right;">
11.377063
</td>
<td style="text-align:right;">
282.73260
</td>
<td style="text-align:right;">
154.59635
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count3
</td>
<td style="text-align:left;">
7
</td>
<td style="text-align:left;">
Twitter for iPhone
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
3962
</td>
<td style="text-align:right;">
12202.9374
</td>
<td style="text-align:right;">
12446.9754
</td>
<td style="text-align:right;">
9669.0
</td>
<td style="text-align:right;">
10498.42808
</td>
<td style="text-align:right;">
9077.9598
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
369530
</td>
<td style="text-align:right;">
369521
</td>
<td style="text-align:right;">
7.905802
</td>
<td style="text-align:right;">
182.04888
</td>
<td style="text-align:right;">
197.74549
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count4
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:left;">
Twitter Web Client
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
10718
</td>
<td style="text-align:right;">
658.1469
</td>
<td style="text-align:right;">
4174.2519
</td>
<td style="text-align:right;">
78.0
</td>
<td style="text-align:right;">
167.51551
</td>
<td style="text-align:right;">
114.1602
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
272776
</td>
<td style="text-align:right;">
272776
</td>
<td style="text-align:right;">
35.585319
</td>
<td style="text-align:right;">
1929.41928
</td>
<td style="text-align:right;">
40.32012
</td>
</tr>
</tbody>
</table>
</div>
<div id="section-some-demonstration" class="section level3">
<h3>Some demonstration</h3>
<p>An example (a pretty ugly one, using base R) of a plot is in the
code. We will see how this can be improved later. One easy fix we’ll
apply later is to rotate the x axis to show the number, not the
notation. Unfortunately base R doesn’t let us do that easily.</p>
<pre class="r"><code>hist(trump_tweets$favorite_count)</code></pre>
<p><img src="snippet_matchR_clustered_quizy_files/figure-html/basic-histograms-1.png" width="768" /></p>
</div>
<div id="section-section" class="section level3">
<h3></h3>
<p>We’re also going to quickly demonstrate how part of this page works.
The page is built on an r package called <code>learnr</code> which lets
me insert exercises that you can run yourselves, and lets me check your
answers! Cool right?</p>
<p>Here’s a really basic example. In the box below, I want you to
<code>assign</code> the value 2 to the variable x. In r we assign by
using the operator <code>&lt;-</code> This is preceded by the name of
the variable, in this case <code>x</code> And followed by the thing
we’re assigning, in this case <code>2</code> So <code>y &lt;- 3*3</code>
assigns the value <code>9</code> to the variable <code>y</code> Delete
the code in the box to to <code>assign</code> the value 2 to the
variable x; the checker looks at your code rather than the output in
this case.</p>
<div class="tutorial-exercise" data-label="example" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>1+1</code></pre>
<pre><code>[1] 2</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":true,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<div class="tutorial-exercise-support" data-label="example-solution"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0">
<pre class="text"><code>x &lt;- 2</code></pre>
</div>
<p>We’ve made it easy below. You don’t need to <em>write</em> your own
code, just copy and paste our examples into the correct slot!</p>
</div>
</div>
<div id="section-q1-what-is-the-relationship-between-retweets-and-likes"
class="section level2">
<h2>Q1 What is the relationship between retweets and likes?</h2>
<div class="panel panel-default">
<div data-label="relationship-sol" class="tutorial-question panel-body">
<div id="relationship-sol-answer_container" class="shiny-html-output"></div>
<div id="relationship-sol-message_container" class="shiny-html-output"></div>
<div id="relationship-sol-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<p>You can run the code below, or see the outputs underneath.</p>
<strong>Block 8</strong>
<div class="tutorial-exercise" data-label="relationship-1"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="5">
<pre class="text"><code>################### BLOCK 8 ########################
ggplot(trump_tweets, aes(x = retweet_count, y = favorite_count)) +
  geom_point(shape = 1) </code></pre>
<p><img src="snippet_matchR_clustered_quizy_files/figure-html/relationship-1-1.png" width="768" /></p>
<pre class="text"><code>##
cor.test(trump_tweets$retweet_count,trump_tweets$favorite_count)</code></pre>
<pre><code>
    Pearson&#39;s product-moment correlation

data:  trump_tweets$retweet_count and trump_tweets$favorite_count
t = 331.95, df = 20759, p-value &lt; 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.9151331 0.9194466
sample estimates:
      cor 
0.9173168 </code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 7</strong>
<div class="tutorial-exercise" data-label="relationship-2"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="10">
<pre class="text"><code>################### BLOCK 7 ########################
trump_tweets %&gt;% 
  select(created_at,retweet_count,favorite_count) %&gt;%
  pivot_longer(cols = c(&quot;retweet_count&quot;,&quot;favorite_count&quot;), names_to = &quot;variable&quot;, values_to = &quot;count&quot;) %&gt;%
     mutate(created_at=as.Date(created_at, format = &quot;%Y-%m-%d&quot;)) %&gt;%
  filter(created_at &gt; &quot;2015-01-01&quot;) %&gt;%
  ggplot(aes(x=created_at, y=count, group=variable, colour=variable)) + 
  geom_line() +
  geom_point()</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/relationship-2-1.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 17</strong>
<div class="tutorial-exercise" data-label="relationship-3"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="10">
<pre class="text"><code>################### BLOCK 17 ########################
#We&#39;ll compare the bottom 25% of retweet counts to the rest by average favourites
ggplot(trump_tweets %&gt;% mutate(retweeted = ifelse(retweet_count &gt; quantile(retweet_count, .25), &quot;Y&quot;, &quot;N&quot;)), 
       aes(x = retweeted, y = favorite_count)) + 
  geom_bar(stat=&quot;summary&quot;, fun=&quot;mean&quot;, fill=&quot;steelblue&quot;, position = &quot;dodge&quot;) + 
  theme_minimal() +
  stat_summary(geom = &quot;errorbar&quot;, fun.data = &quot;mean_se&quot;, position = &quot;dodge&quot;)</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/relationship-3-1.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-q2-what-source-has-the-highest-sentiment"
class="section level2">
<h2>Q2 What source has the highest sentiment?</h2>
<p>For this one, we can see four tweets in the same range, what are the
values and their content (the tweet text)?</p>
<div class="panel panel-default">
<div data-label="max-sol" class="tutorial-question panel-body">
<div id="max-sol-answer_container" class="shiny-html-output"></div>
<div id="max-sol-message_container" class="shiny-html-output"></div>
<div id="max-sol-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<p>You can run the code below, or see the outputs underneath.</p>
<strong>Block 13</strong>
<div class="tutorial-exercise" data-label="max" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="25">
<pre class="text"><code>################### BLOCK 13 ############################
trump_tweets %&gt;% 
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;)) %&gt;% #filter to the two biggest sources
  ggplot(aes(x = factor(source), y = ave_sentiment)) +  #note, you&#39;ll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn&#39;t add new information.
  geom_boxplot() +
  stat_summary(
    fun = mean, geom=&quot;point&quot;, shape=5, size=4)</code></pre>
<p><img src="snippet_matchR_clustered_quizy_files/figure-html/max-1.png" width="768" /></p>
<pre class="text"><code>################### 
trump_tweets %&gt;% 
  filter(source == &quot;Twitter for Android&quot;) %&gt;%
  slice_max(ave_sentiment, n = 1) %&gt;%
  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we&#39;re interested in</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["text"],"name":[1],"type":["chr"],"align":["left"]},{"label":["retweet_count"],"name":[2],"type":["int"],"align":["right"]},{"label":["favorite_count"],"name":[3],"type":["int"],"align":["right"]},{"label":["created_at"],"name":[4],"type":["dttm"],"align":["right"]},{"label":["source"],"name":[5],"type":["chr"],"align":["left"]},{"label":["ave_sentiment"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"I hate to say it, but the Republican Convention was far more interesting (with a much more beautiful set) than the Democratic Convention!","2":"10248","3":"46692","4":"2016-07-26 21:08:50","5":"Twitter for Android","6":"1.623285"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="text"><code>################### 
trump_tweets %&gt;% 
  filter(source == &quot;Twitter for iPhone&quot;) %&gt;%
  slice_max(ave_sentiment, n = 1) %&gt;%
  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we&#39;re interested in</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["text"],"name":[1],"type":["chr"],"align":["left"]},{"label":["retweet_count"],"name":[2],"type":["int"],"align":["right"]},{"label":["favorite_count"],"name":[3],"type":["int"],"align":["right"]},{"label":["created_at"],"name":[4],"type":["dttm"],"align":["right"]},{"label":["source"],"name":[5],"type":["chr"],"align":["left"]},{"label":["ave_sentiment"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"I am truly honored and grateful for receiving SO much support from our American heroes...https://t.co/S9bvbysiOr https://t.co/JJQncd3zhf","2":"10271","3":"26351","4":"2016-09-16 12:58:14","5":"Twitter for iPhone","6":"1.82"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":true,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 2</strong>
<div class="tutorial-exercise" data-label="max-2" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="10">
<pre class="text"><code>################### BLOCK 2 ########################
ggplot(trump_tweets, 
       aes(x = source, y = ave_sentiment)) + 
  geom_bar(stat=&quot;summary&quot;, fun=&quot;mean&quot;, fill=&quot;steelblue&quot;, position = &quot;dodge&quot;) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/max-2-1.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div
id="section-q3-how-do-iphone-and-android-compare-in-terms-of-number-of-words"
class="section level2">
<h2>Q3 How do iphone and android compare in terms of number of
words?</h2>
<div class="panel panel-default">
<div data-label="summary1-sol" class="tutorial-question panel-body">
<div id="summary1-sol-answer_container" class="shiny-html-output"></div>
<div id="summary1-sol-message_container" class="shiny-html-output"></div>
<div id="summary1-sol-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<p>You can run the code below, or see the outputs underneath.</p>
<strong>Block 5</strong>
<div class="tutorial-exercise" data-label="summary1" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="10">
<pre class="text"><code>################### BLOCK 5 ########################
ggplot(trump_tweets %&gt;% filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;)), 
       aes(x = source, y = word_count)) + 
  geom_bar(stat=&quot;identity&quot;, fill=&quot;steelblue&quot;) + 
  theme_minimal() +
  stat_summary(geom = &quot;errorbar&quot;, fun.data = mean_se, position = &quot;dodge&quot;)</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/summary1-1.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":true,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 6</strong>
<div class="tutorial-exercise" data-label="summary1-1"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="25">
<pre class="text"><code>################### BLOCK 6 ########################
#Second version - sometimes it&#39;s useful to think about what information is included in different representations
trump_tweets %&gt;% 
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)) %&gt;% #filter to the  biggest sources
  ggplot(aes(x = factor(source), y = word_count)) +  #note, you&#39;ll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn&#39;t add new information.
  geom_boxplot() +
  stat_summary(
    fun = mean, geom=&quot;point&quot;, shape=5, size=4)</code></pre>
<p><img src="snippet_matchR_clustered_quizy_files/figure-html/summary1-1-1.png" width="768" /></p>
<pre class="text"><code>############
kable(table(trump_tweets$source), output = &quot;html&quot;)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
Var1
</th>
<th style="text-align:right;">
Freq
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Facebook
</td>
<td style="text-align:right;">
104
</td>
</tr>
<tr>
<td style="text-align:left;">
Instagram
</td>
<td style="text-align:right;">
133
</td>
</tr>
<tr>
<td style="text-align:left;">
Media Studio
</td>
<td style="text-align:right;">
114
</td>
</tr>
<tr>
<td style="text-align:left;">
Mobile Web (M5)
</td>
<td style="text-align:right;">
54
</td>
</tr>
<tr>
<td style="text-align:left;">
Neatly For BlackBerry 10
</td>
<td style="text-align:right;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
Periscope
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:left;">
TweetDeck
</td>
<td style="text-align:right;">
468
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitlonger
</td>
<td style="text-align:right;">
22
</td>
</tr>
<tr>
<td style="text-align:left;">
TwitLonger Beta
</td>
<td style="text-align:right;">
288
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter Ads
</td>
<td style="text-align:right;">
96
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter for Android
</td>
<td style="text-align:right;">
4652
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter for BlackBerry
</td>
<td style="text-align:right;">
78
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter for iPad
</td>
<td style="text-align:right;">
39
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter for iPhone
</td>
<td style="text-align:right;">
3962
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter for Websites
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter Mirror for iPad
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter QandA
</td>
<td style="text-align:right;">
10
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter Web Client
</td>
<td style="text-align:right;">
10718
</td>
</tr>
<tr>
<td style="text-align:left;">
Vine - Make a Scene
</td>
<td style="text-align:right;">
10
</td>
</tr>
</tbody>
</table>
<pre class="text"><code>############
ggplot(trump_tweets %&gt;% filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)), 
       aes(x = word_count, fill = source)) + 
  geom_histogram(alpha = .5, position = &#39;identity&#39;,  
                 aes(y = ..density..*width), show.legend = FALSE) + 
  facet_grid (. ~ source) ##..density..*width shows the proportion effectively normalised by group (iphone and android).  #note use of &#39;density&#39; because we have unequal  counts in each dataset, and this lets us understand the data as a proportion which accounts for the unequal samples Alpha is the transparency level.</code></pre>
<pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/summary1-1-2.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 1</strong>
<div class="tutorial-exercise" data-label="summary1-2"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="25">
<pre class="text"><code>################### BLOCK 1 ########################
#First version  - sometimes it&#39;s useful to think about what information is included in different representations
trump_tweets %&gt;% 
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)) %&gt;% #filter to the  biggest sources
  ggplot(aes(x = factor(source), y = word_count)) +  #note, you&#39;ll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn&#39;t add new information.
  geom_boxplot() +
  stat_summary(
    fun = mean, geom=&quot;point&quot;, shape=5, size=4) +
  geom_jitter()</code></pre>
<p><img src="snippet_matchR_clustered_quizy_files/figure-html/summary1-2-1.png" width="768" /></p>
<pre class="text"><code>############
kable(table(trump_tweets$source), output = &quot;html&quot;)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
Var1
</th>
<th style="text-align:right;">
Freq
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Facebook
</td>
<td style="text-align:right;">
104
</td>
</tr>
<tr>
<td style="text-align:left;">
Instagram
</td>
<td style="text-align:right;">
133
</td>
</tr>
<tr>
<td style="text-align:left;">
Media Studio
</td>
<td style="text-align:right;">
114
</td>
</tr>
<tr>
<td style="text-align:left;">
Mobile Web (M5)
</td>
<td style="text-align:right;">
54
</td>
</tr>
<tr>
<td style="text-align:left;">
Neatly For BlackBerry 10
</td>
<td style="text-align:right;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
Periscope
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:left;">
TweetDeck
</td>
<td style="text-align:right;">
468
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitlonger
</td>
<td style="text-align:right;">
22
</td>
</tr>
<tr>
<td style="text-align:left;">
TwitLonger Beta
</td>
<td style="text-align:right;">
288
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter Ads
</td>
<td style="text-align:right;">
96
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter for Android
</td>
<td style="text-align:right;">
4652
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter for BlackBerry
</td>
<td style="text-align:right;">
78
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter for iPad
</td>
<td style="text-align:right;">
39
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter for iPhone
</td>
<td style="text-align:right;">
3962
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter for Websites
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter Mirror for iPad
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter QandA
</td>
<td style="text-align:right;">
10
</td>
</tr>
<tr>
<td style="text-align:left;">
Twitter Web Client
</td>
<td style="text-align:right;">
10718
</td>
</tr>
<tr>
<td style="text-align:left;">
Vine - Make a Scene
</td>
<td style="text-align:right;">
10
</td>
</tr>
</tbody>
</table>
<pre class="text"><code>############
ggplot(trump_tweets %&gt;% 
         filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)), 
       aes(x = word_count, fill = source)) + 
  geom_histogram(alpha = .5, position = &#39;identity&#39;) + 
  facet_grid (. ~ source) </code></pre>
<pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/summary1-2-2.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-q4-what-nrc-sentiments-occur-in-each-source"
class="section level2">
<h2>Q4 What NRC sentiments occur in each source ?</h2>
<div class="panel panel-default">
<div data-label="props-sol" class="tutorial-question panel-body">
<div id="props-sol-answer_container" class="shiny-html-output"></div>
<div id="props-sol-message_container" class="shiny-html-output"></div>
<div id="props-sol-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<p>You can run the code below, or see the outputs underneath.</p>
<strong>Block 9</strong>
<div class="tutorial-exercise" data-label="props" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="20">
<pre class="text"><code>################### BLOCK 9 ########################
# Scatterplot
trump_tweets %&gt;%
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)) %&gt;% #filter to the  biggest sources
  mutate(senti_score = recode(sentiment_nrc, &quot;negative&quot; = 1, &quot;anger&quot; = 2, &quot;disgust&quot; = 3, &quot;fear&quot; = 4, &quot;sadness&quot; = 5, &quot;surprise&quot; = 6, &quot;anticipation&quot; = 7, &quot;trust&quot; = 8, &quot;joy&quot; = 9, &quot;positive&quot; = 10)) %&gt;%
  ggplot(aes(x = senti_score, y = retweet_count)) +
  geom_point(shape = 1) +
  theme(axis.text.x = element_text(angle = 90)) + 
  facet_grid( ~ source)</code></pre>
<p><img src="snippet_matchR_clustered_quizy_files/figure-html/props-1.png" width="768" /></p>
<pre class="text"><code># \\n
#A correlation plot
trump_tweets %&gt;%
    filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)) %&gt;% #filter to the  biggest sources
  mutate(senti_score = recode(sentiment_nrc, &quot;negative&quot; = 1, &quot;anger&quot; = 2, &quot;disgust&quot; = 3, &quot;fear&quot; = 4, &quot;sadness&quot; = 5, &quot;surprise&quot; = 6, &quot;anticipation&quot; = 7, &quot;trust&quot; = 8, &quot;joy&quot; = 9, &quot;positive&quot; = 10)) %&gt;%
  select(retweet_count,senti_score) %&gt;%
  na.omit() %&gt;%
  cor() %&gt;%
  corrplot()</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/props-2.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":true,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 11</strong>
<div class="tutorial-exercise" data-label="props-1" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="20">
<pre class="text"><code>################### BLOCK 11 ########################
# Stacked
trump_tweets %&gt;% 
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;) &amp; !is.na(sentiment_nrc)) %&gt;% #filter to the  biggest sources)
  ggplot(aes(x=source, y=sentiment_nrc, fill=sentiment_nrc)) + 
    geom_bar(position=&quot;stack&quot;, stat=&quot;identity&quot;) +
    theme(axis.text.x = element_text(angle = 90))</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/props-1-1.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 12</strong>
<div class="tutorial-exercise" data-label="props-2" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="47">
<pre class="text"><code>################### BLOCK 12 ########################
# Stacked + percent - You might decide to remove tweetdeck too given it&#39;s a much smaller sample
trump_tweets %&gt;% 
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;) &amp; !is.na(sentiment_nrc)) %&gt;% #filter to the  biggest sources)
  mutate(sentiment_nrc = factor(sentiment_nrc, levels=c(&quot;negative&quot;, &quot;anger&quot;, &quot;disgust&quot;, &quot;fear&quot;, &quot;sadness&quot;, &quot;surprise&quot;,  &quot;joy&quot;, &quot;trust&quot;, &quot;anticipation&quot;, &quot;positive&quot;))) %&gt;%
ggplot(aes(x=source)) + 
    geom_bar(aes(fill=sentiment_nrc), position=&quot;fill&quot;) + 
  theme(axis.text.x = element_text(angle = 90)) + 
  scale_fill_manual(values = c(&quot;negative&quot; = &quot;#D55E00&quot;,
                               &quot;anger&quot; = &quot;#CC79A7&quot;, 
                               &quot;disgust&quot; = &quot;#E69F00&quot;, 
                               &quot;fear&quot; = &quot;#F0E442&quot;, 
                               &quot;sadness&quot; = &quot;red&quot;, 
                               &quot;surprise&quot; = &quot;#999999&quot;,
                               &quot;positive&quot; = &quot;#009E73&quot;, 
                               &quot;anticipation&quot; = &quot;#56B4E9&quot;, 
                               &quot;trust&quot; = &quot;green&quot;, 
                               &quot;joy&quot; = &quot;#0072B2&quot;)
                    )</code></pre>
<p><img src="snippet_matchR_clustered_quizy_files/figure-html/props-2-1.png" width="768" /></p>
<pre class="text"><code>#attempt to use palettes that are visible to those with colour blindness. This palette should be ok.  Two biggest groups are ordered (by the mutate statement) so you can read from the bottom or the top. 
#trust, joy, anticipation, all intersect with positive 
#anger, disgust, fear, sadness all intersect with negative
#surprise is sometimes positive or negative with interactive https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
</div>
<div id="section-q5-how-are-nrc-sentiment-source-and-rts-associated"
class="section level2">
<h2>Q5 How are NRC sentiment, source, and RTs associated?</h2>
<div class="panel panel-default">
<div data-label="association-sol" class="tutorial-question panel-body">
<div id="association-sol-answer_container" class="shiny-html-output"></div>
<div id="association-sol-message_container" class="shiny-html-output"></div>
<div id="association-sol-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<p>You can run the code below, or see the outputs underneath.</p>
<strong>Block 9</strong>
<div class="tutorial-exercise" data-label="association"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="21">
<pre class="text"><code>################### BLOCK 9 ########################
# Scatterplot
trump_tweets %&gt;%
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)) %&gt;% #filter to the  biggest sources
  mutate(senti_score = recode(sentiment_nrc, &quot;negative&quot; = 1, &quot;anger&quot; = 2, &quot;disgust&quot; = 3, &quot;fear&quot; = 4, &quot;sadness&quot; = 5, &quot;surprise&quot; = 6, &quot;anticipation&quot; = 7, &quot;trust&quot; = 8, &quot;joy&quot; = 9, &quot;positive&quot; = 10)) %&gt;%
  ggplot(aes(x = senti_score, y = retweet_count)) +
  geom_point(shape = 1) +
  theme(axis.text.x = element_text(angle = 90)) + 
  facet_grid( ~ source)</code></pre>
<p><img src="snippet_matchR_clustered_quizy_files/figure-html/association-1.png" width="768" /></p>
<pre class="text"><code>#A correlation plot
trump_tweets %&gt;%
    filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)) %&gt;% #filter to the  biggest sources
  mutate(senti_score = recode(sentiment_nrc, &quot;negative&quot; = 1, &quot;anger&quot; = 2, &quot;disgust&quot; = 3, &quot;fear&quot; = 4, &quot;sadness&quot; = 5, &quot;surprise&quot; = 6, &quot;anticipation&quot; = 7, &quot;trust&quot; = 8, &quot;joy&quot; = 9, &quot;positive&quot; = 10)) %&gt;%
  select(retweet_count,senti_score) %&gt;%
  na.omit() %&gt;%
  cor() %&gt;%
  corrplot()</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/association-2.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":true,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 3</strong>
<div class="tutorial-exercise" data-label="association-1"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="21">
<pre class="text"><code>################### BLOCK 3 ########################
print(&quot;I am a blank chunk&quot;)</code></pre>
<pre><code>[1] &quot;I am a blank chunk&quot;</code></pre>
<pre class="text"><code>#Sometimes, the best way to address a question at this stage of the investigation is to break it down
#In this case, you&#39;ve looked at sentiment by source, and you&#39;ve looked at RTs by source.
#You could also look at RT by source, to investigate at a descriptive level
#(There&#39;s some sample code to do that in the feedback - it shows there&#39;s not much difference probably)
#But, at this stage you&#39;re getting into the need to do different kinds of analysis, but there&#39;s still more value to get from sticking to descriptives.
#To use this block, copy all this commented text</code></pre>
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 10</strong>
<div class="tutorial-exercise" data-label="association-2"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="41">
<pre class="text"><code>################### BLOCK 10 ########################
#Boxplots by source and sentiment 
trump_tweets %&gt;% 
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)) %&gt;% #filter to the  biggest sources
  ggplot(aes(x = factor(sentiment_nrc), y = retweet_count)) + 
  geom_boxplot() +
  stat_summary(
    fun = mean, geom=&quot;point&quot;, shape=5, size=4) +
  facet_grid(. ~ source) +
  theme(axis.text.x = element_text(angle = 90))</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/association-2-1.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 4</strong>
<div class="tutorial-exercise" data-label="association-3"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="41">
<pre class="text"><code>################### BLOCK 4 ########################
#You can have this one for free - heatmaps can be useful sometimes, but not like this. 
#trump_tweets %&gt;% mutate(reply_to = ifelse(in_reply_to_user_id_str &gt; 0, &quot;Y&quot;, &quot;N&quot;)) %&gt;% 
trump_tweets %&gt;% filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)) %&gt;%
  ggplot(aes(x = sentiment_nrc, source)) +
  geom_tile(aes(fill = retweet_count)) +
  theme(axis.text.x = element_text(angle = 90))</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/association-3-1.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<details>
<summary>
<em>click here for another couple of analyses of this data</em> (may not
look expandable…it is)
</summary>
<pre class="r"><code>trump_tweets %&gt;% 
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;) &amp; !is.na(sentiment_nrc)) %&gt;% #filter to the  biggest sources
  ggplot(aes(x = factor(sentiment_nrc), y = retweet_count)) + 
  geom_boxplot() +
  stat_summary(
    fun = mean, geom=&quot;point&quot;, shape=5, size=4) +
  theme(axis.text.x = element_text(angle = 90))</code></pre>
<p><img src="snippet_matchR_clustered_quizy_files/figure-html/extensions-1.png" width="768" /></p>
<pre class="r"><code>trump_tweets %&gt;% 
  filter(source %in% c(&quot;Twitter for Android&quot;,&quot;Twitter for iPhone&quot;,&quot;TweetDeck&quot;,&quot;Twitter Web Client&quot;)) %&gt;% 
  select(c(favorite_count,retweet_count,sentiment_nrc)) %&gt;%
  psych::describeBy(favorite_count + retweet_count ~ sentiment_nrc, data = ., mat = T) %&gt;%
  kable(digits=2, &quot;html&quot;)</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
item
</th>
<th style="text-align:left;">
group1
</th>
<th style="text-align:right;">
vars
</th>
<th style="text-align:right;">
n
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
median
</th>
<th style="text-align:right;">
trimmed
</th>
<th style="text-align:right;">
mad
</th>
<th style="text-align:right;">
min
</th>
<th style="text-align:right;">
max
</th>
<th style="text-align:right;">
range
</th>
<th style="text-align:right;">
skew
</th>
<th style="text-align:right;">
kurtosis
</th>
<th style="text-align:right;">
se
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
favorite_count1
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
anger
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2150
</td>
<td style="text-align:right;">
15068.46
</td>
<td style="text-align:right;">
31654.82
</td>
<td style="text-align:right;">
269.0
</td>
<td style="text-align:right;">
6603.25
</td>
<td style="text-align:right;">
388.44
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
237614
</td>
<td style="text-align:right;">
237614
</td>
<td style="text-align:right;">
2.83
</td>
<td style="text-align:right;">
8.83
</td>
<td style="text-align:right;">
682.69
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count2
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
anticipation
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3016
</td>
<td style="text-align:right;">
12294.71
</td>
<td style="text-align:right;">
29587.90
</td>
<td style="text-align:right;">
178.0
</td>
<td style="text-align:right;">
4081.85
</td>
<td style="text-align:right;">
259.46
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
249249
</td>
<td style="text-align:right;">
249249
</td>
<td style="text-align:right;">
3.35
</td>
<td style="text-align:right;">
13.01
</td>
<td style="text-align:right;">
538.76
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count3
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:left;">
disgust
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
355
</td>
<td style="text-align:right;">
14776.23
</td>
<td style="text-align:right;">
44260.51
</td>
<td style="text-align:right;">
221.0
</td>
<td style="text-align:right;">
4946.62
</td>
<td style="text-align:right;">
309.86
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
616217
</td>
<td style="text-align:right;">
616217
</td>
<td style="text-align:right;">
8.08
</td>
<td style="text-align:right;">
96.38
</td>
<td style="text-align:right;">
2349.10
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count4
</td>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
fear
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
810
</td>
<td style="text-align:right;">
22473.18
</td>
<td style="text-align:right;">
46489.31
</td>
<td style="text-align:right;">
323.0
</td>
<td style="text-align:right;">
11772.05
</td>
<td style="text-align:right;">
461.09
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
633253
</td>
<td style="text-align:right;">
633253
</td>
<td style="text-align:right;">
4.45
</td>
<td style="text-align:right;">
39.84
</td>
<td style="text-align:right;">
1633.47
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count5
</td>
<td style="text-align:left;">
5
</td>
<td style="text-align:left;">
joy
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
968
</td>
<td style="text-align:right;">
11679.13
</td>
<td style="text-align:right;">
32337.04
</td>
<td style="text-align:right;">
69.0
</td>
<td style="text-align:right;">
3085.73
</td>
<td style="text-align:right;">
102.30
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
289942
</td>
<td style="text-align:right;">
289942
</td>
<td style="text-align:right;">
4.13
</td>
<td style="text-align:right;">
19.96
</td>
<td style="text-align:right;">
1039.35
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count6
</td>
<td style="text-align:left;">
6
</td>
<td style="text-align:left;">
negative
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2467
</td>
<td style="text-align:right;">
19263.33
</td>
<td style="text-align:right;">
36478.03
</td>
<td style="text-align:right;">
382.0
</td>
<td style="text-align:right;">
10201.07
</td>
<td style="text-align:right;">
553.01
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
275392
</td>
<td style="text-align:right;">
275392
</td>
<td style="text-align:right;">
2.29
</td>
<td style="text-align:right;">
5.51
</td>
<td style="text-align:right;">
734.42
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count7
</td>
<td style="text-align:left;">
7
</td>
<td style="text-align:left;">
positive
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4419
</td>
<td style="text-align:right;">
14879.47
</td>
<td style="text-align:right;">
32117.36
</td>
<td style="text-align:right;">
266.0
</td>
<td style="text-align:right;">
6445.63
</td>
<td style="text-align:right;">
382.51
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
390826
</td>
<td style="text-align:right;">
390826
</td>
<td style="text-align:right;">
3.18
</td>
<td style="text-align:right;">
14.61
</td>
<td style="text-align:right;">
483.15
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count8
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:left;">
sadness
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
58
</td>
<td style="text-align:right;">
9840.34
</td>
<td style="text-align:right;">
27486.64
</td>
<td style="text-align:right;">
225.5
</td>
<td style="text-align:right;">
3336.00
</td>
<td style="text-align:right;">
320.24
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
173510
</td>
<td style="text-align:right;">
173510
</td>
<td style="text-align:right;">
4.23
</td>
<td style="text-align:right;">
20.23
</td>
<td style="text-align:right;">
3609.17
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count9
</td>
<td style="text-align:left;">
9
</td>
<td style="text-align:left;">
surprise
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
577
</td>
<td style="text-align:right;">
5773.99
</td>
<td style="text-align:right;">
17752.33
</td>
<td style="text-align:right;">
39.0
</td>
<td style="text-align:right;">
911.15
</td>
<td style="text-align:right;">
44.48
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
120615
</td>
<td style="text-align:right;">
120615
</td>
<td style="text-align:right;">
3.98
</td>
<td style="text-align:right;">
16.80
</td>
<td style="text-align:right;">
739.04
</td>
</tr>
<tr>
<td style="text-align:left;">
favorite_count10
</td>
<td style="text-align:left;">
10
</td>
<td style="text-align:left;">
trust
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
811
</td>
<td style="text-align:right;">
17060.30
</td>
<td style="text-align:right;">
31848.44
</td>
<td style="text-align:right;">
932.0
</td>
<td style="text-align:right;">
9460.70
</td>
<td style="text-align:right;">
1378.82
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
267584
</td>
<td style="text-align:right;">
267584
</td>
<td style="text-align:right;">
2.77
</td>
<td style="text-align:right;">
10.37
</td>
<td style="text-align:right;">
1118.35
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count1
</td>
<td style="text-align:left;">
11
</td>
<td style="text-align:left;">
anger
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2150
</td>
<td style="text-align:right;">
4466.66
</td>
<td style="text-align:right;">
8736.59
</td>
<td style="text-align:right;">
367.5
</td>
<td style="text-align:right;">
2394.25
</td>
<td style="text-align:right;">
517.43
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
141644
</td>
<td style="text-align:right;">
141644
</td>
<td style="text-align:right;">
4.05
</td>
<td style="text-align:right;">
34.72
</td>
<td style="text-align:right;">
188.42
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count2
</td>
<td style="text-align:left;">
12
</td>
<td style="text-align:left;">
anticipation
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
3016
</td>
<td style="text-align:right;">
3271.95
</td>
<td style="text-align:right;">
7284.45
</td>
<td style="text-align:right;">
255.5
</td>
<td style="text-align:right;">
1433.17
</td>
<td style="text-align:right;">
370.65
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
120661
</td>
<td style="text-align:right;">
120661
</td>
<td style="text-align:right;">
4.29
</td>
<td style="text-align:right;">
33.13
</td>
<td style="text-align:right;">
132.64
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count3
</td>
<td style="text-align:left;">
13
</td>
<td style="text-align:left;">
disgust
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
355
</td>
<td style="text-align:right;">
4853.64
</td>
<td style="text-align:right;">
16586.93
</td>
<td style="text-align:right;">
325.0
</td>
<td style="text-align:right;">
1964.42
</td>
<td style="text-align:right;">
458.12
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
272776
</td>
<td style="text-align:right;">
272776
</td>
<td style="text-align:right;">
12.24
</td>
<td style="text-align:right;">
189.61
</td>
<td style="text-align:right;">
880.34
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count4
</td>
<td style="text-align:left;">
14
</td>
<td style="text-align:left;">
fear
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
810
</td>
<td style="text-align:right;">
6391.70
</td>
<td style="text-align:right;">
13295.65
</td>
<td style="text-align:right;">
474.5
</td>
<td style="text-align:right;">
3602.89
</td>
<td style="text-align:right;">
654.57
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
220796
</td>
<td style="text-align:right;">
220796
</td>
<td style="text-align:right;">
6.65
</td>
<td style="text-align:right;">
86.07
</td>
<td style="text-align:right;">
467.16
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count5
</td>
<td style="text-align:left;">
15
</td>
<td style="text-align:left;">
joy
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
968
</td>
<td style="text-align:right;">
3109.61
</td>
<td style="text-align:right;">
7913.04
</td>
<td style="text-align:right;">
94.0
</td>
<td style="text-align:right;">
1151.57
</td>
<td style="text-align:right;">
139.36
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
85555
</td>
<td style="text-align:right;">
85555
</td>
<td style="text-align:right;">
4.46
</td>
<td style="text-align:right;">
26.28
</td>
<td style="text-align:right;">
254.33
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count6
</td>
<td style="text-align:left;">
16
</td>
<td style="text-align:left;">
negative
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2467
</td>
<td style="text-align:right;">
5413.89
</td>
<td style="text-align:right;">
9632.69
</td>
<td style="text-align:right;">
538.0
</td>
<td style="text-align:right;">
3218.19
</td>
<td style="text-align:right;">
760.57
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
127507
</td>
<td style="text-align:right;">
127507
</td>
<td style="text-align:right;">
3.05
</td>
<td style="text-align:right;">
17.13
</td>
<td style="text-align:right;">
193.94
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count7
</td>
<td style="text-align:left;">
17
</td>
<td style="text-align:left;">
positive
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4419
</td>
<td style="text-align:right;">
4086.04
</td>
<td style="text-align:right;">
8450.62
</td>
<td style="text-align:right;">
365.0
</td>
<td style="text-align:right;">
2077.99
</td>
<td style="text-align:right;">
517.43
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
141853
</td>
<td style="text-align:right;">
141853
</td>
<td style="text-align:right;">
4.34
</td>
<td style="text-align:right;">
34.48
</td>
<td style="text-align:right;">
127.12
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count8
</td>
<td style="text-align:left;">
18
</td>
<td style="text-align:left;">
sadness
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
58
</td>
<td style="text-align:right;">
2788.24
</td>
<td style="text-align:right;">
6686.84
</td>
<td style="text-align:right;">
312.5
</td>
<td style="text-align:right;">
1331.79
</td>
<td style="text-align:right;">
455.90
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
43455
</td>
<td style="text-align:right;">
43455
</td>
<td style="text-align:right;">
4.22
</td>
<td style="text-align:right;">
21.26
</td>
<td style="text-align:right;">
878.03
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count9
</td>
<td style="text-align:left;">
19
</td>
<td style="text-align:left;">
surprise
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
577
</td>
<td style="text-align:right;">
1903.86
</td>
<td style="text-align:right;">
5947.01
</td>
<td style="text-align:right;">
37.0
</td>
<td style="text-align:right;">
451.86
</td>
<td style="text-align:right;">
40.03
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
87163
</td>
<td style="text-align:right;">
87163
</td>
<td style="text-align:right;">
7.11
</td>
<td style="text-align:right;">
79.86
</td>
<td style="text-align:right;">
247.58
</td>
</tr>
<tr>
<td style="text-align:left;">
retweet_count10
</td>
<td style="text-align:left;">
20
</td>
<td style="text-align:left;">
trust
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
811
</td>
<td style="text-align:right;">
4722.25
</td>
<td style="text-align:right;">
7917.76
</td>
<td style="text-align:right;">
885.0
</td>
<td style="text-align:right;">
2966.72
</td>
<td style="text-align:right;">
1279.48
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
72934
</td>
<td style="text-align:right;">
72934
</td>
<td style="text-align:right;">
2.84
</td>
<td style="text-align:right;">
12.65
</td>
<td style="text-align:right;">
278.03
</td>
</tr>
</tbody>
</table>
</details>
</div>
<div id="section-q6-what-kind-of-language-do-trumps-tweets-use"
class="section level2">
<h2>Q6 What kind of language do Trump’s tweets use?</h2>
<div class="panel panel-default">
<div data-label="words-sol" class="tutorial-question panel-body">
<div id="words-sol-answer_container" class="shiny-html-output"></div>
<div id="words-sol-message_container" class="shiny-html-output"></div>
<div id="words-sol-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<p>You can run the code below, or see the outputs underneath.</p>
<strong>Block 15</strong>
<div class="tutorial-exercise" data-label="words" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="11">
<pre class="text"><code>################### BLOCK 15 ########################
wc &lt;- tweet_words %&gt;%
  anti_join(stop_words) %&gt;%
  count(word) %&gt;%
  slice_max(n, n = 500)</code></pre>
<pre><code>Joining, by = &quot;word&quot;</code></pre>
<pre class="text"><code>ggwordcloud2(wc, color = &quot;random-dark&quot;, shape = &quot;star&quot;)</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/words-1.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":true,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<strong>Block 16</strong>
<div class="tutorial-exercise" data-label="words-1" data-completion="1"
data-diagnostics="1" data-startover="1" data-lines="21">
<pre class="text"><code>################### BLOCK 16 ########################
#wordcloud2(wc, color = &quot;black&quot;, maxRotation = 0, minRotation = 0, shape = &quot;diamond&quot;) #diamond is just a square
#wordcloud - different package - makes simple ones too, and has an inbuilt function for comparison.  We&#39;ll do that for 2 groups positive and negative words (but you could use more)
tweet_words %&gt;%
  inner_join(get_sentiments(&quot;bing&quot;)) %&gt;%
  count(word, sentiment, sort = TRUE) %&gt;%
  reshape2::acast(word ~ sentiment, value.var = &quot;n&quot;, fill = 0) %&gt;%  #ideally rewrite using spread from dplyr
  comparison.cloud(term.matrix = ., 
                   colors = c(&quot;grey20&quot;, &quot;grey80&quot;),
                   max.words = 100,
                   rot.per = 0)</code></pre>
<pre><code>Joining, by = &quot;word&quot;</code></pre>
<img src="snippet_matchR_clustered_quizy_files/figure-html/words-1-1.png" width="768" />
<script type="application/json" data-ui-opts="1">{"engine":"r","has_checker":false,"caption":"<span data-i18n=\"text.enginecap\" data-i18n-opts=\"{&quot;engine&quot;:&quot;R&quot;}\">R Code<\/span>"}</script>
</div>
<details>
<summary>
<em>Click here for some extra insight into those tweets</em>
</summary>
<pre class="r"><code>android_iphone_or &lt;- tweet_words %&gt;%
  count(word, source) %&gt;%
  pivot_wider(names_from = &quot;source&quot;, values_from = &quot;n&quot;, values_fill = 0) %&gt;%
  rename(&quot;Android&quot;= &quot;Twitter for Android&quot;, &quot;iPhone&quot; = &quot;Twitter for iPhone&quot;) %&gt;%
  select(c(word,Android,iPhone)) %&gt;%
  mutate(or = (Android + 0.5) / (sum(Android) - Android + 0.5) / 
           ( (iPhone + 0.5) / (sum(iPhone) - iPhone + 0.5)))

#This shows frequently used words (&gt;100 times) sorted by the odds ratio, which is a statistical representation that quantifies differences in how likely a thing (a word in this case) is likely to occur in different groups (iphone vs android, treatment vs placebo, etc.)
android_iphone_or %&gt;% filter(Android+iPhone &gt; 100) %&gt;%
  arrange(desc(or))</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["word"],"name":[1],"type":["chr"],"align":["left"]},{"label":["Android"],"name":[2],"type":["int"],"align":["right"]},{"label":["iPhone"],"name":[3],"type":["int"],"align":["right"]},{"label":["or"],"name":[4],"type":["dbl"],"align":["right"]}],"data":[{"1":"obama","2":"256","3":"53","4":"4.037593289"},{"1":"@cnn","2":"105","3":"25","4":"3.473030919"},{"1":"total","2":"123","3":"35","4":"2.920834056"},{"1":"sad","2":"91","3":"27","4":"2.791845372"},{"1":"ted","2":"87","3":"28","4":"2.575756926"},{"1":"terrible","2":"76","3":"25","4":"2.516374849"},{"1":"wow","2":"121","3":"41","4":"2.457471005"},{"1":"bad","2":"208","3":"75","4":"2.320969918"},{"1":"ratings","2":"74","3":"28","4":"2.192298555"},{"1":"nice","2":"100","3":"39","4":"2.134564751"},{"1":"money","2":"106","3":"43","4":"2.054070132"},{"1":"cruz","2":"113","3":"47","4":"2.004857606"},{"1":"debate","2":"86","3":"36","4":"1.987653011"},{"1":"amazing","2":"134","3":"57","4":"1.963102719"},{"1":"@foxandfriends","2":"83","3":"36","4":"1.918560662"},{"1":"totally","2":"109","3":"48","4":"1.894053955"},{"1":"interviewed","2":"93","3":"41","4":"1.889701034"},{"1":"doesnt","2":"76","3":"35","4":"1.806951436"},{"1":"dont","2":"162","3":"78","4":"1.737430752"},{"1":"remember","2":"75","3":"36","4":"1.734369456"},{"1":"president","2":"248","3":"120","4":"1.732563596"},{"1":"deal","2":"92","3":"45","4":"1.704872173"},{"1":"crooked","2":"159","3":"79","4":"1.683711922"},{"1":"stop","2":"70","3":"36","4":"1.619290602"},{"1":"hillary","2":"305","3":"162","4":"1.579759161"},{"1":"morning","2":"95","3":"51","4":"1.554921906"},{"1":"night","2":"133","3":"72","4":"1.544574167"},{"1":"enjoy","2":"128","3":"72","4":"1.486522713"},{"1":"world","2":"95","3":"54","4":"1.469186987"},{"1":"polls","2":"67","3":"39","4":"1.432377917"},{"1":"win","2":"120","3":"73","4":"1.374667096"},{"1":"job","2":"117","3":"73","4":"1.340333650"},{"1":"time","2":"203","3":"130","4":"1.308065613"},{"1":"people","2":"384","3":"255","4":"1.263459832"},{"1":"@foxnews","2":"81","3":"54","4":"1.253331856"},{"1":"speech","2":"68","3":"46","4":"1.234530535"},{"1":"failing","2":"67","3":"46","4":"1.216475150"},{"1":"trump","2":"238","3":"168","4":"1.186976211"},{"1":"country","2":"192","3":"136","4":"1.182384709"},{"1":"tonight","2":"159","3":"113","4":"1.178039108"},{"1":"china","2":"63","3":"47","4":"1.120137359"},{"1":"love","2":"68","3":"54","4":"1.053041938"},{"1":"crowd","2":"70","3":"56","4":"1.045412529"},{"1":"national","2":"91","3":"73","4":"1.043011641"},{"1":"media","2":"117","3":"96","4":"1.020114227"},{"1":"massive","2":"63","3":"54","4":"0.976045011"},{"1":"poll","2":"124","3":"108","4":"0.961150375"},{"1":"obamacare","2":"82","3":"74","4":"0.927540266"},{"1":"republican","2":"74","3":"67","4":"0.924467847"},{"1":"record","2":"60","3":"55","4":"0.913073112"},{"1":"hard","2":"74","3":"69","4":"0.897806216"},{"1":"day","2":"99","3":"98","4":"0.845832459"},{"1":"wonderful","2":"61","3":"61","4":"0.837472335"},{"1":"watch","2":"90","3":"90","4":"0.837344240"},{"1":"iowa","2":"72","3":"73","4":"0.826003456"},{"1":"election","2":"67","3":"68","4":"0.825193599"},{"1":"clinton","2":"142","3":"146","4":"0.814151801"},{"1":"happy","2":"51","3":"53","4":"0.806155165"},{"1":"russia","2":"55","3":"59","4":"0.781095067"},{"1":"story","2":"47","3":"56","4":"0.703916197"},{"1":"live","2":"48","3":"60","4":"0.671146957"},{"1":"campaign","2":"56","3":"75","4":"0.626348156"},{"1":"jobs","2":"90","3":"121","4":"0.623073317"},{"1":"united","2":"53","3":"72","4":"0.617642215"},{"1":"bill","2":"46","3":"65","4":"0.594222265"},{"1":"america","2":"161","3":"245","4":"0.549127941"},{"1":"carolina","2":"44","3":"69","4":"0.535836825"},{"1":"news","2":"97","3":"186","4":"0.436472764"},{"1":"vote","2":"62","3":"126","4":"0.412910030"},{"1":"tomorrow","2":"62","3":"130","4":"0.400201760"},{"1":"florida","2":"37","3":"81","4":"0.384839316"},{"1":"democrats","2":"30","3":"74","4":"0.342425010"},{"1":"support","2":"32","3":"97","4":"0.278612163"},{"1":"american","2":"38","3":"119","4":"0.269137724"},{"1":"north","2":"24","3":"88","4":"0.231407135"},{"1":"honor","2":"22","3":"82","4":"0.228004543"},{"1":"fake","2":"33","3":"143","4":"0.194839490"},{"1":"tax","2":"24","3":"135","4":"0.150909911"},{"1":"join","2":"3","3":"197","4":"0.014752597"},{"1":"#trump2016","2":"4","3":"411","4":"0.009040332"},{"1":"#makeamericagreatagain","2":"0","3":"294","4":"0.001408778"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>android_iphone_or %&gt;% filter(Android+iPhone &gt; 100) %&gt;%
  arrange(or)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["word"],"name":[1],"type":["chr"],"align":["left"]},{"label":["Android"],"name":[2],"type":["int"],"align":["right"]},{"label":["iPhone"],"name":[3],"type":["int"],"align":["right"]},{"label":["or"],"name":[4],"type":["dbl"],"align":["right"]}],"data":[{"1":"#makeamericagreatagain","2":"0","3":"294","4":"0.001408778"},{"1":"#trump2016","2":"4","3":"411","4":"0.009040332"},{"1":"join","2":"3","3":"197","4":"0.014752597"},{"1":"tax","2":"24","3":"135","4":"0.150909911"},{"1":"fake","2":"33","3":"143","4":"0.194839490"},{"1":"honor","2":"22","3":"82","4":"0.228004543"},{"1":"north","2":"24","3":"88","4":"0.231407135"},{"1":"american","2":"38","3":"119","4":"0.269137724"},{"1":"support","2":"32","3":"97","4":"0.278612163"},{"1":"democrats","2":"30","3":"74","4":"0.342425010"},{"1":"florida","2":"37","3":"81","4":"0.384839316"},{"1":"tomorrow","2":"62","3":"130","4":"0.400201760"},{"1":"vote","2":"62","3":"126","4":"0.412910030"},{"1":"news","2":"97","3":"186","4":"0.436472764"},{"1":"carolina","2":"44","3":"69","4":"0.535836825"},{"1":"america","2":"161","3":"245","4":"0.549127941"},{"1":"bill","2":"46","3":"65","4":"0.594222265"},{"1":"united","2":"53","3":"72","4":"0.617642215"},{"1":"jobs","2":"90","3":"121","4":"0.623073317"},{"1":"campaign","2":"56","3":"75","4":"0.626348156"},{"1":"live","2":"48","3":"60","4":"0.671146957"},{"1":"story","2":"47","3":"56","4":"0.703916197"},{"1":"russia","2":"55","3":"59","4":"0.781095067"},{"1":"happy","2":"51","3":"53","4":"0.806155165"},{"1":"clinton","2":"142","3":"146","4":"0.814151801"},{"1":"election","2":"67","3":"68","4":"0.825193599"},{"1":"iowa","2":"72","3":"73","4":"0.826003456"},{"1":"watch","2":"90","3":"90","4":"0.837344240"},{"1":"wonderful","2":"61","3":"61","4":"0.837472335"},{"1":"day","2":"99","3":"98","4":"0.845832459"},{"1":"hard","2":"74","3":"69","4":"0.897806216"},{"1":"record","2":"60","3":"55","4":"0.913073112"},{"1":"republican","2":"74","3":"67","4":"0.924467847"},{"1":"obamacare","2":"82","3":"74","4":"0.927540266"},{"1":"poll","2":"124","3":"108","4":"0.961150375"},{"1":"massive","2":"63","3":"54","4":"0.976045011"},{"1":"media","2":"117","3":"96","4":"1.020114227"},{"1":"national","2":"91","3":"73","4":"1.043011641"},{"1":"crowd","2":"70","3":"56","4":"1.045412529"},{"1":"love","2":"68","3":"54","4":"1.053041938"},{"1":"china","2":"63","3":"47","4":"1.120137359"},{"1":"tonight","2":"159","3":"113","4":"1.178039108"},{"1":"country","2":"192","3":"136","4":"1.182384709"},{"1":"trump","2":"238","3":"168","4":"1.186976211"},{"1":"failing","2":"67","3":"46","4":"1.216475150"},{"1":"speech","2":"68","3":"46","4":"1.234530535"},{"1":"@foxnews","2":"81","3":"54","4":"1.253331856"},{"1":"people","2":"384","3":"255","4":"1.263459832"},{"1":"time","2":"203","3":"130","4":"1.308065613"},{"1":"job","2":"117","3":"73","4":"1.340333650"},{"1":"win","2":"120","3":"73","4":"1.374667096"},{"1":"polls","2":"67","3":"39","4":"1.432377917"},{"1":"world","2":"95","3":"54","4":"1.469186987"},{"1":"enjoy","2":"128","3":"72","4":"1.486522713"},{"1":"night","2":"133","3":"72","4":"1.544574167"},{"1":"morning","2":"95","3":"51","4":"1.554921906"},{"1":"hillary","2":"305","3":"162","4":"1.579759161"},{"1":"stop","2":"70","3":"36","4":"1.619290602"},{"1":"crooked","2":"159","3":"79","4":"1.683711922"},{"1":"deal","2":"92","3":"45","4":"1.704872173"},{"1":"president","2":"248","3":"120","4":"1.732563596"},{"1":"remember","2":"75","3":"36","4":"1.734369456"},{"1":"dont","2":"162","3":"78","4":"1.737430752"},{"1":"doesnt","2":"76","3":"35","4":"1.806951436"},{"1":"interviewed","2":"93","3":"41","4":"1.889701034"},{"1":"totally","2":"109","3":"48","4":"1.894053955"},{"1":"@foxandfriends","2":"83","3":"36","4":"1.918560662"},{"1":"amazing","2":"134","3":"57","4":"1.963102719"},{"1":"debate","2":"86","3":"36","4":"1.987653011"},{"1":"cruz","2":"113","3":"47","4":"2.004857606"},{"1":"money","2":"106","3":"43","4":"2.054070132"},{"1":"nice","2":"100","3":"39","4":"2.134564751"},{"1":"ratings","2":"74","3":"28","4":"2.192298555"},{"1":"bad","2":"208","3":"75","4":"2.320969918"},{"1":"wow","2":"121","3":"41","4":"2.457471005"},{"1":"terrible","2":"76","3":"25","4":"2.516374849"},{"1":"ted","2":"87","3":"28","4":"2.575756926"},{"1":"sad","2":"91","3":"27","4":"2.791845372"},{"1":"total","2":"123","3":"35","4":"2.920834056"},{"1":"@cnn","2":"105","3":"25","4":"3.473030919"},{"1":"obama","2":"256","3":"53","4":"4.037593289"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</details>
<p>
<script type="application/shiny-prerendered" data-context="server-start">
#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.
#It would be sensible to also include RAppArmor
library(learnr)
library(gradethis)

gradethis::gradethis_setup()
tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)

knitr::opts_chunk$set(
	fig.height = 6,
	fig.width = 8,
	warning = FALSE,
	cache = TRUE
)

tut_reptitle <- "matchR"

###############################
###############################
##############################
#install.packages(c("psych","ggplot2","doBy","reshape2","knitr","lattice"))
  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries
  sh(library(ggplot2))  #for graphs and plots
  sh(library(psych))    #for statistical measures and testing
  #sh(library(doBy))     #for group by analysis dplyr covers this
  #sh(library(reshape2)) #for data wrangling
  sh(library(knitr))    #for rendering markdown
  #sh(library(lattice))  #just to illustrate another histogram function 
  library(dslabs)
  library(shiny) #shouldn't be necessary but...
 # install.packages("remotes")
  #remotes::install_github("rstudio-education/gradethis")

  library(textdata)
  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep 
  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too
  #library(wordcloud2) #This may not work well when knitted
  library(kableExtra)
  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score 
  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object
  #this is great! https://github.com/trinker/sentimentr#examples
  library(tidyverse)
  library(tidytext)
  library(corrplot)
#detach(package:plyr)

#library(rsconnect)
#deployApp(appName = "Snippet_matchR)
##############################################################
#############LOAD DATA HERE######################################
##############################################################

if(!file.exists("matchr.RData")) {
  
#trump_tweets <- data("trump_tweets")
data("trump_tweets")
##############AND we're going to do some tidying up #############

links <- "https://t.co/[A-Za-z\\d]+|&amp;" #regex to get rid of picture links
tweet_words <- trump_tweets %>% 
  mutate(text = str_replace_all(text, links, ""))  %>%
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% stop_words$word &
           !str_detect(word, "^\\d+$")) %>%
  mutate(word = str_replace(word, "^'", ""))

##############And add sentiment analysis columns for later #########
bing <- get_sentiments("bing")
afinn <- get_sentiments("afinn")

#loughran <- get_sentiments("loughran") %>% count(sentiment)
#get_sentiments("nrc") %>% count(sentiment) 

nrc <- get_sentiments("nrc") %>%
  select(word, sentiment)

#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.

trump_tweets %<>% 
  dplyr::mutate(sent_split = get_sentences(text)) %>%
  dplyr::mutate(sentiment_by(sent_split)) %>%
  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, "Negative",
                           ifelse(ave_sentiment > 0.2, "Positive","Neutral")))


tt_senti2 <- tweet_words %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(id_str) %>%
  dplyr::summarise(sentiment_afinn = mean(value)) 

#mode <- function(codes){which.max(tabulate(codes))}
mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below

tt_senti3 <- tweet_words %>%
  inner_join(get_sentiments("nrc")) %>%
  group_by(id_str) %>%
  dplyr::summarise(sentiment_nrc = mode(sentiment))
                
#join the sentiment to the original twitter data
#trump_tweets <- left_join(trump_tweets, tt_senti, by = c("id_str" = "index")) 
trump_tweets <- left_join(trump_tweets, tt_senti2, by = "id_str") 
trump_tweets <- left_join(trump_tweets, tt_senti3, by = "id_str") 

#write_csv(trump_tweets,"trump_tweets.csv")
#write_csv(tweet_words,"tweet_words.csv")
save(trump_tweets,tweet_words, file = "matchr.RData")

rm(tt_senti2,tt_senti3)

} else {
  #trump_tweets <- read_csv("trump_tweets.csv")
  #tweet_words <- read_csv(tweet_words,"tweet_words.csv")
  load("matchr.RData")
}
#table(tweet_words %>% inner_join(get_sentiments("nrc")) %>% select(sentiment)) 
#afinn is also pretty cool

</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::prepare_tutorial_state(session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::i18n_observe_tutorial_language(input, session)
</script>


<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::event_trigger(session, "session_stop")
      })
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-explore-datasets-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-explore-datasets-code-editor`)), session)
output$`tutorial-exercise-explore-datasets-output` <- renderUI({
  `tutorial-exercise-explore-datasets-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "explore-datasets", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "explore-datasets", code = "#View the first 10 rows of the dataset\nhead(trump_tweets)", 
        opts = list(label = "\"explore-datasets\"", exercise = "TRUE", 
            exercise.lines = "2"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, test_cases = NULL, 
    options = list(eval = TRUE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "explore-datasets", exercise = TRUE, exercise.lines = 2, 
        code = c("#View the first 10 rows of the dataset", "head(trump_tweets)"
        ), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/explore-datasets_de733e076ca9714059f08e16417eaa9b", 
        params.src = "explore-datasets, exercise = TRUE, exercise.lines=2", 
        fig.alt = NULL, fig.num = 0, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-example-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-example-code-editor`)), session)
output$`tutorial-exercise-example-output` <- renderUI({
  `tutorial-exercise-example-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "example", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "example", code = "1+1", opts = list(
        label = "\"example\"", exercise = "TRUE"), engine = "r")), 
    code_check = structure("grade_code()", chunk_opts = list(
        label = "example-code-check")), error_check = NULL, check = NULL, 
    solution = structure(c("x <- 2", ""), chunk_opts = list(label = "example-solution")), 
    test_cases = NULL, options = list(eval = TRUE, echo = TRUE, 
        results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, 
        prompt = FALSE, comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "example", exercise = TRUE, code = "1+1", out.width.px = 768, 
        out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/example_d54ac8170995b12cb7495a46723a7220", 
        params.src = "example, exercise = TRUE", fig.alt = NULL, 
        fig.num = 0, exercise.df_print = "paged"), engine = "r"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "relationship-sol", 
    question = structure("What is the relationship between retweets and likes?", html = TRUE, class = c("html", 
    "character")), answers = list(structure(list(id = "lnr_ans_b1d8aff", 
        option = "Block 8", value = "Block 8", label = structure("Block 8", html = TRUE, class = c("html", 
        "character")), correct = TRUE, message = structure("Yes! There are other ways to explore the data, but if we care about relationship between two features, a scatterplot (and correlation coefficient) are a good place to start exploring.", html = TRUE, class = c("html", 
        "character")), type = "literal"), class = c("tutorial_question_answer", 
    "tutorial_quiz_answer")), structure(list(id = "lnr_ans_e655cb6", 
        option = "Block 7", value = "Block 7", label = structure("Block 7", html = TRUE, class = c("html", 
        "character")), correct = FALSE, message = structure("Is time a relevant variable? Are favourites and retweets comparable on the same scales?", html = TRUE, class = c("html", 
        "character")), type = "literal"), class = c("tutorial_question_answer", 
    "tutorial_quiz_answer")), structure(list(id = "lnr_ans_f0bbdb7", 
        option = "Block 17", value = "Block 17", label = structure("Block 17", html = TRUE, class = c("html", 
        "character")), correct = FALSE, message = structure("The error bars are good! But you can see how this only really gives us insight into 1 feature of the data, and it doesn&#39;t tell us anything about the relationship between the two variables.", html = TRUE, class = c("html", 
        "character")), type = "literal"), class = c("tutorial_question_answer", 
    "tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
    "character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
    "character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", 
    "character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
    "character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
    "character")), message = NULL, post_message = NULL), ids = list(
        answer = "relationship-sol-answer", question = "relationship-sol"), 
    loading = structure("<strong>Loading:<\u002fstrong> \nWhat is the relationship between retweets and likes?\n<br/><br/><br/>", html = TRUE, class = c("html", 
    "character")), random_answer_order = FALSE, allow_retry = TRUE, 
    seed = 640054183.201952, options = list()), class = c("learnr_radio", 
"tutorial_question")), session = session)
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-relationship-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-relationship-1-code-editor`)), session)
output$`tutorial-exercise-relationship-1-output` <- renderUI({
  `tutorial-exercise-relationship-1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "relationship-1", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "relationship-1", code = "################### BLOCK 8 ########################\nggplot(trump_tweets, aes(x = retweet_count, y = favorite_count)) +\n  geom_point(shape = 1) \n##\ncor.test(trump_tweets$retweet_count,trump_tweets$favorite_count)\n", 
        opts = list(label = "\"relationship-1\"", exercise = "TRUE", 
            exercise.lines = "5"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, test_cases = NULL, 
    options = list(eval = TRUE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "relationship-1", exercise = TRUE, exercise.lines = 5, 
        code = c("################### BLOCK 8 ########################", 
        "ggplot(trump_tweets, aes(x = retweet_count, y = favorite_count)) +", 
        "  geom_point(shape = 1) ", "##", "cor.test(trump_tweets$retweet_count,trump_tweets$favorite_count)", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/relationship-1_9ac259cb6f81d233a25462b3d79be877", 
        params.src = "relationship-1, exercise = TRUE, exercise.lines=5", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-relationship-2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-relationship-2-code-editor`)), session)
output$`tutorial-exercise-relationship-2-output` <- renderUI({
  `tutorial-exercise-relationship-2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "relationship-2", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "relationship-2", code = "################### BLOCK 7 ########################\ntrump_tweets %>% \n  select(created_at,retweet_count,favorite_count) %>%\n  pivot_longer(cols = c(\"retweet_count\",\"favorite_count\"), names_to = \"variable\", values_to = \"count\") %>%\n     mutate(created_at=as.Date(created_at, format = \"%Y-%m-%d\")) %>%\n  filter(created_at > \"2015-01-01\") %>%\n  ggplot(aes(x=created_at, y=count, group=variable, colour=variable)) + \n  geom_line() +\n  geom_point()\n", 
        opts = list(label = "\"relationship-2\"", exercise = "TRUE", 
            exercise.lines = "10"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, test_cases = NULL, 
    options = list(eval = TRUE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "relationship-2", exercise = TRUE, exercise.lines = 10, 
        code = c("################### BLOCK 7 ########################", 
        "trump_tweets %>% ", "  select(created_at,retweet_count,favorite_count) %>%", 
        "  pivot_longer(cols = c(\"retweet_count\",\"favorite_count\"), names_to = \"variable\", values_to = \"count\") %>%", 
        "     mutate(created_at=as.Date(created_at, format = \"%Y-%m-%d\")) %>%", 
        "  filter(created_at > \"2015-01-01\") %>%", "  ggplot(aes(x=created_at, y=count, group=variable, colour=variable)) + ", 
        "  geom_line() +", "  geom_point()", ""), out.width.px = 768, 
        out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/relationship-2_90747f1e925df6308c6760a1ae99eaab", 
        params.src = "relationship-2, exercise = TRUE, exercise.lines=10", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-relationship-3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-relationship-3-code-editor`)), session)
output$`tutorial-exercise-relationship-3-output` <- renderUI({
  `tutorial-exercise-relationship-3-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "relationship-3", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "relationship-3", code = "################### BLOCK 17 ########################\n#We'll compare the bottom 25% of retweet counts to the rest by average favourites\nggplot(trump_tweets %>% mutate(retweeted = ifelse(retweet_count > quantile(retweet_count, .25), \"Y\", \"N\")), \n       aes(x = retweeted, y = favorite_count)) + \n  geom_bar(stat=\"summary\", fun=\"mean\", fill=\"steelblue\", position = \"dodge\") + \n  theme_minimal() +\n  stat_summary(geom = \"errorbar\", fun.data = \"mean_se\", position = \"dodge\")\n", 
        opts = list(label = "\"relationship-3\"", exercise = "TRUE", 
            exercise.lines = "10"), engine = "r")), code_check = NULL, 
    error_check = NULL, check = NULL, solution = NULL, test_cases = NULL, 
    options = list(eval = TRUE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "relationship-3", exercise = TRUE, exercise.lines = 10, 
        code = c("################### BLOCK 17 ########################", 
        "#We'll compare the bottom 25% of retweet counts to the rest by average favourites", 
        "ggplot(trump_tweets %>% mutate(retweeted = ifelse(retweet_count > quantile(retweet_count, .25), \"Y\", \"N\")), ", 
        "       aes(x = retweeted, y = favorite_count)) + ", 
        "  geom_bar(stat=\"summary\", fun=\"mean\", fill=\"steelblue\", position = \"dodge\") + ", 
        "  theme_minimal() +", "  stat_summary(geom = \"errorbar\", fun.data = \"mean_se\", position = \"dodge\")", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/relationship-3_69749089e75dbf7a4c9b2b8e12ca2b5f", 
        params.src = "relationship-3, exercise = TRUE, exercise.lines=10", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "max-sol", question = structure("What source has the highest sentiment?", html = TRUE, class = c("html", 
"character")), answers = list(structure(list(id = "lnr_ans_584e468", 
    option = "Block 13", value = "Block 13", label = structure("Block 13", html = TRUE, class = c("html", 
    "character")), correct = TRUE, message = structure("Yes! What do we mean by max? Highest individual values? (susceptible to outliers), or a measure of the central tendency such as the mean or median? In exploration with this kind of data, it is often interesting to explore both the quantifiaction, and the underlying data (text, image, etc.) because it helps readers understand the data&#39;s meaning.", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_2513a46", 
    option = "Block 2", value = "Block 2", label = structure("Block 2", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = structure("Bar charts are sometimes useful, especially with error bars which help us understand something of the distribution, but they only show 1 value and thus give little insight into the data", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
"character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
"character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", 
"character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
"character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
"character")), message = NULL, post_message = NULL), ids = list(
    answer = "max-sol-answer", question = "max-sol"), loading = structure("<strong>Loading:<\u002fstrong> \nWhat source has the highest sentiment?\n<br/><br/><br/>", html = TRUE, class = c("html", 
"character")), random_answer_order = FALSE, allow_retry = TRUE, 
    seed = 1129499492.97404, options = list()), class = c("learnr_radio", 
"tutorial_question")), session = session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-max-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-max-code-editor`)), session)
output$`tutorial-exercise-max-output` <- renderUI({
  `tutorial-exercise-max-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "max", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "max", code = "################### BLOCK 13 ############################\ntrump_tweets %>% \n  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\")) %>% #filter to the two biggest sources\n  ggplot(aes(x = factor(source), y = ave_sentiment)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.\n  geom_boxplot() +\n  stat_summary(\n    fun = mean, geom=\"point\", shape=5, size=4)\n################### \ntrump_tweets %>% \n  filter(source == \"Twitter for Android\") %>%\n  slice_max(ave_sentiment, n = 1) %>%\n  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in\n################### \ntrump_tweets %>% \n  filter(source == \"Twitter for iPhone\") %>%\n  slice_max(ave_sentiment, n = 1) %>%\n  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in\n", 
        opts = list(label = "\"max\"", exercise = "TRUE", exercise.lines = "25", 
            eval = "T"), engine = "r")), code_check = structure(c("grade_code()", 
    "#block 13", "#Distractor is block 2", "#For interest, you could also look at the lowest sentiment two", 
    "# trump_tweets %>% ", "#   filter(source == \"Twitter for Android\") %>%", 
    "#   slice_min(ave_sentiment, n = 1) %>%", "#   select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in", 
    "# ", "# trump_tweets %>% ", "#   filter(source == \"Twitter for iPhone\") %>%", 
    "#   slice_min(ave_sentiment, n = 1) %>%", "#   select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in"
    ), chunk_opts = list(label = "max-code-check", eval = FALSE, 
        include = FALSE)), error_check = NULL, check = NULL, 
    solution = NULL, test_cases = NULL, options = list(eval = TRUE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        size = "normalsize", background = "#F7F7F7", strip.white = TRUE, 
        cache = 3, cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "max", exercise = TRUE, exercise.lines = 25, 
        code = c("################### BLOCK 13 ############################", 
        "trump_tweets %>% ", "  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\")) %>% #filter to the two biggest sources", 
        "  ggplot(aes(x = factor(source), y = ave_sentiment)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.", 
        "  geom_boxplot() +", "  stat_summary(", "    fun = mean, geom=\"point\", shape=5, size=4)", 
        "################### ", "trump_tweets %>% ", "  filter(source == \"Twitter for Android\") %>%", 
        "  slice_max(ave_sentiment, n = 1) %>%", "  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in", 
        "################### ", "trump_tweets %>% ", "  filter(source == \"Twitter for iPhone\") %>%", 
        "  slice_max(ave_sentiment, n = 1) %>%", "  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/max_21c4b16a87a20731b45bd4a917c17720", 
        params.src = "max, exercise = TRUE, exercise.lines=25, eval = T", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-max-2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-max-2-code-editor`)), session)
output$`tutorial-exercise-max-2-output` <- renderUI({
  `tutorial-exercise-max-2-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "max-2", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "max-2", code = "################### BLOCK 2 ########################\nggplot(trump_tweets, \n       aes(x = source, y = ave_sentiment)) + \n  geom_bar(stat=\"summary\", fun=\"mean\", fill=\"steelblue\", position = \"dodge\") + \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90))\n", 
        opts = list(label = "\"max-2\"", exercise = "TRUE", exercise.lines = "10", 
            eval = "T"), engine = "r")), code_check = NULL, error_check = NULL, 
    check = NULL, solution = NULL, test_cases = NULL, options = list(
        eval = TRUE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 3, cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "max-2", exercise = TRUE, exercise.lines = 10, 
        code = c("################### BLOCK 2 ########################", 
        "ggplot(trump_tweets, ", "       aes(x = source, y = ave_sentiment)) + ", 
        "  geom_bar(stat=\"summary\", fun=\"mean\", fill=\"steelblue\", position = \"dodge\") + ", 
        "  theme_minimal() +", "  theme(axis.text.x = element_text(angle = 90))", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/max-2_598496962b942b26e00be5fb798ecac5", 
        params.src = "max-2, exercise = TRUE, exercise.lines=10, eval = T", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "summary1-sol", 
    question = structure("How do iphone and android compare in terms of number of words?", html = TRUE, class = c("html", 
    "character")), answers = list(structure(list(id = "lnr_ans_60c66b4", 
        option = "Block 5", value = "Block 5", label = structure("Block 5", html = TRUE, class = c("html", 
        "character")), correct = FALSE, message = structure("as above, bar charts display a very limited range of information", html = TRUE, class = c("html", 
        "character")), type = "literal"), class = c("tutorial_question_answer", 
    "tutorial_quiz_answer")), structure(list(id = "lnr_ans_157498c", 
        option = "Block 1", value = "Block 1", label = structure("Block 1", html = TRUE, class = c("html", 
        "character")), correct = FALSE, message = structure("Note, showing the boxplots and the variation in the underlying data (and size) is the interest here. Jitter is often useful to show the actual underlying data, but here while it gives us insight into the smaller sample for tweetdeck there are too many points for it to be meaningful. \n You can also see differences in the histogram, in this block using absolute values makes it hard to compare. That more tweets came from one source is not the key issue, we want to understand when a tweet is from source x, are there differences in length; normalising by frequency lets us do that (density)", html = TRUE, class = c("html", 
        "character")), type = "literal"), class = c("tutorial_question_answer", 
    "tutorial_quiz_answer")), structure(list(id = "lnr_ans_10bb63b", 
        option = "Block 6", value = "Block 6", label = structure("Block 6", html = TRUE, class = c("html", 
        "character")), correct = TRUE, message = structure("Yes! Note, showing the boxplots and the variation in the underlying data (and size) is the interest here. Jitter is often useful to show the actual underlying data, but here while it gives us insight into the smaller sample for tweetdeck there are too many points for it to be meaningful. \n You can also see differences in the histogram, in block 1 using absolute values makes it hard to compare. That more tweets came from one source is not the key issue, we want to understand when a tweet is from source x, are there differences in length; normalising by frequency lets us do that (density)", html = TRUE, class = c("html", 
        "character")), type = "literal"), class = c("tutorial_question_answer", 
    "tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
    "character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
    "character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", 
    "character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
    "character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
    "character")), message = NULL, post_message = NULL), ids = list(
        answer = "summary1-sol-answer", question = "summary1-sol"), 
    loading = structure("<strong>Loading:<\u002fstrong> \nHow do iphone and android compare in terms of number of words?\n<br/><br/><br/>", html = TRUE, class = c("html", 
    "character")), random_answer_order = FALSE, allow_retry = TRUE, 
    seed = 1931355972.60064, options = list()), class = c("learnr_radio", 
"tutorial_question")), session = session)
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-summary1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-summary1-code-editor`)), session)
output$`tutorial-exercise-summary1-output` <- renderUI({
  `tutorial-exercise-summary1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "summary1", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "summary1", code = "################### BLOCK 5 ########################\nggplot(trump_tweets %>% filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\")), \n       aes(x = source, y = word_count)) + \n  geom_bar(stat=\"identity\", fill=\"steelblue\") + \n  theme_minimal() +\n  stat_summary(geom = \"errorbar\", fun.data = mean_se, position = \"dodge\")\n", 
        opts = list(label = "\"summary1\"", exercise = "TRUE", 
            exercise.lines = "10", eval = "T"), engine = "r")), 
    code_check = structure(c("grade_code()", "", "#block 6", 
    "#Distractors are block 5, and 1", "", "#Note, showing the boxplots and the variation in the underlying data (and size) is the interest here. Jitter is often useful to show the actual underlying data, but here while it gives us insight into the smaller sample for tweetdeck there are too many points for it to be meaningful. "
    ), chunk_opts = list(label = "summary1-code-check", eval = FALSE, 
        include = FALSE)), error_check = NULL, check = NULL, 
    solution = NULL, test_cases = NULL, options = list(eval = TRUE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        size = "normalsize", background = "#F7F7F7", strip.white = TRUE, 
        cache = 3, cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "summary1", exercise = TRUE, exercise.lines = 10, 
        code = c("################### BLOCK 5 ########################", 
        "ggplot(trump_tweets %>% filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\")), ", 
        "       aes(x = source, y = word_count)) + ", "  geom_bar(stat=\"identity\", fill=\"steelblue\") + ", 
        "  theme_minimal() +", "  stat_summary(geom = \"errorbar\", fun.data = mean_se, position = \"dodge\")", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/summary1_9f40e6bfcab2ef1bc81df2fcc61cd64f", 
        params.src = "summary1, exercise = TRUE, exercise.lines=10, eval = T", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-summary1-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-summary1-1-code-editor`)), session)
output$`tutorial-exercise-summary1-1-output` <- renderUI({
  `tutorial-exercise-summary1-1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "summary1-1", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "summary1-1", code = "################### BLOCK 6 ########################\n#Second version - sometimes it's useful to think about what information is included in different representations\ntrump_tweets %>% \n  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources\n  ggplot(aes(x = factor(source), y = word_count)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.\n  geom_boxplot() +\n  stat_summary(\n    fun = mean, geom=\"point\", shape=5, size=4)\n############\nkable(table(trump_tweets$source), output = \"html\")\n############\nggplot(trump_tweets %>% filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")), \n       aes(x = word_count, fill = source)) + \n  geom_histogram(alpha = .5, position = 'identity',  \n                 aes(y = ..density..*width), show.legend = FALSE) + \n  facet_grid (. ~ source) ##..density..*width shows the proportion effectively normalised by group (iphone and android).  #note use of 'density' because we have unequal  counts in each dataset, and this lets us understand the data as a proportion which accounts for the unequal samples Alpha is the transparency level.\n", 
        opts = list(label = "\"summary1-1\"", exercise = "TRUE", 
            exercise.lines = "25", eval = "T"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    test_cases = NULL, options = list(eval = TRUE, echo = TRUE, 
        results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, 
        prompt = FALSE, comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "summary1-1", exercise = TRUE, exercise.lines = 25, 
        code = c("################### BLOCK 6 ########################", 
        "#Second version - sometimes it's useful to think about what information is included in different representations", 
        "trump_tweets %>% ", "  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources", 
        "  ggplot(aes(x = factor(source), y = word_count)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.", 
        "  geom_boxplot() +", "  stat_summary(", "    fun = mean, geom=\"point\", shape=5, size=4)", 
        "############", "kable(table(trump_tweets$source), output = \"html\")", 
        "############", "ggplot(trump_tweets %>% filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")), ", 
        "       aes(x = word_count, fill = source)) + ", "  geom_histogram(alpha = .5, position = 'identity',  ", 
        "                 aes(y = ..density..*width), show.legend = FALSE) + ", 
        "  facet_grid (. ~ source) ##..density..*width shows the proportion effectively normalised by group (iphone and android).  #note use of 'density' because we have unequal  counts in each dataset, and this lets us understand the data as a proportion which accounts for the unequal samples Alpha is the transparency level.", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/summary1-1_046903168c8b1fbcfadfa8a049bfc9f5", 
        params.src = "summary1-1, exercise = TRUE, exercise.lines=25, eval = T", 
        fig.alt = NULL, fig.num = 2, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-summary1-2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-summary1-2-code-editor`)), session)
output$`tutorial-exercise-summary1-2-output` <- renderUI({
  `tutorial-exercise-summary1-2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "summary1-2", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "summary1-2", code = "################### BLOCK 1 ########################\n#First version  - sometimes it's useful to think about what information is included in different representations\ntrump_tweets %>% \n  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources\n  ggplot(aes(x = factor(source), y = word_count)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.\n  geom_boxplot() +\n  stat_summary(\n    fun = mean, geom=\"point\", shape=5, size=4) +\n  geom_jitter()\n############\nkable(table(trump_tweets$source), output = \"html\")\n############\nggplot(trump_tweets %>% \n         filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")), \n       aes(x = word_count, fill = source)) + \n  geom_histogram(alpha = .5, position = 'identity') + \n  facet_grid (. ~ source) \n", 
        opts = list(label = "\"summary1-2\"", exercise = "TRUE", 
            exercise.lines = "25", eval = "T"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    test_cases = NULL, options = list(eval = TRUE, echo = TRUE, 
        results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, 
        prompt = FALSE, comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "summary1-2", exercise = TRUE, exercise.lines = 25, 
        code = c("################### BLOCK 1 ########################", 
        "#First version  - sometimes it's useful to think about what information is included in different representations", 
        "trump_tweets %>% ", "  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources", 
        "  ggplot(aes(x = factor(source), y = word_count)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.", 
        "  geom_boxplot() +", "  stat_summary(", "    fun = mean, geom=\"point\", shape=5, size=4) +", 
        "  geom_jitter()", "############", "kable(table(trump_tweets$source), output = \"html\")", 
        "############", "ggplot(trump_tweets %>% ", "         filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")), ", 
        "       aes(x = word_count, fill = source)) + ", "  geom_histogram(alpha = .5, position = 'identity') + ", 
        "  facet_grid (. ~ source) ", ""), out.width.px = 768, 
        out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/summary1-2_ce661fd717c076a9e073f657bc6db257", 
        params.src = "summary1-2, exercise = TRUE, exercise.lines=25, eval = T", 
        fig.alt = NULL, fig.num = 2, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "props-sol", question = structure("What NRC sentiments occur in each source ?", html = TRUE, class = c("html", 
"character")), answers = list(structure(list(id = "lnr_ans_a3ed26b", 
    option = "Block 9", value = "Block 9", label = structure("Block 9", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = structure("Retweets aren&#39;t relevant to the question, and populating it this way makes it very hard to interpret. Block 12 makes it so much easier to (1) compare across the sources, because of the use of proportions/density instead of absolute values, and (2) the use of colours that help us distinguish the values, and (3) the reordering of the values in a meaningful way, so that the broadly negative values are in the red/brown space and the broadly positive values are in the blue/green space (you should have a rationale for doing this).", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_8c52b62", 
    option = "Block 11", value = "Block 11", label = structure("Block 11", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = structure("This is better. But, (1) what we&#39;re really showing here is a function of (a) frequency of tweets from that source, so, tweetdeck is used less and so appears less, and (b) the colours are hard to interpret against the labels. Block 12 makes it so much easier to (1) compare across the sources, because of the use of proportions/density instead of absolute values, and (2) the use of colours that help us distinguish the values, and (3) the reordering of the values in a meaningful way, so that the broadly negative values are in the red/brown space and the broadly positive values are in the blue/green space (you should have a rationale for doing this).", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_29ed155", 
    option = "Block 12", value = "Block 12", label = structure("Block 12", html = TRUE, class = c("html", 
    "character")), correct = TRUE, message = structure("Great! It&#39;s important to look at the absolute values (i.e., the numbers), but proportions or relative values are often really informative. Block 12 makes it so much easier to (1) compare across the sources, because of the use of proportions/density instead of absolute values, and (2) the use of colours that help us distinguish the values, and (3) the reordering of the values in a meaningful way, so that the broadly negative values are in the red/brown space and the broadly positive values are in the blue/green space (you should have a rationale for doing this).", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
"character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
"character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", 
"character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
"character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
"character")), message = NULL, post_message = NULL), ids = list(
    answer = "props-sol-answer", question = "props-sol"), loading = structure("<strong>Loading:<\u002fstrong> \nWhat NRC sentiments occur in each source ?\n<br/><br/><br/>", html = TRUE, class = c("html", 
"character")), random_answer_order = FALSE, allow_retry = TRUE, 
    seed = 370997965.327241, options = list()), class = c("learnr_radio", 
"tutorial_question")), session = session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-props-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-props-code-editor`)), session)
output$`tutorial-exercise-props-output` <- renderUI({
  `tutorial-exercise-props-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "props", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "props", code = "################### BLOCK 9 ########################\n# Scatterplot\ntrump_tweets %>%\n  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources\n  mutate(senti_score = recode(sentiment_nrc, \"negative\" = 1, \"anger\" = 2, \"disgust\" = 3, \"fear\" = 4, \"sadness\" = 5, \"surprise\" = 6, \"anticipation\" = 7, \"trust\" = 8, \"joy\" = 9, \"positive\" = 10)) %>%\n  ggplot(aes(x = senti_score, y = retweet_count)) +\n  geom_point(shape = 1) +\n  theme(axis.text.x = element_text(angle = 90)) + \n  facet_grid( ~ source)\n# \\\\n\n#A correlation plot\ntrump_tweets %>%\n    filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources\n  mutate(senti_score = recode(sentiment_nrc, \"negative\" = 1, \"anger\" = 2, \"disgust\" = 3, \"fear\" = 4, \"sadness\" = 5, \"surprise\" = 6, \"anticipation\" = 7, \"trust\" = 8, \"joy\" = 9, \"positive\" = 10)) %>%\n  select(retweet_count,senti_score) %>%\n  na.omit() %>%\n  cor() %>%\n  corrplot()\n", 
        opts = list(label = "\"props\"", exercise = "TRUE", exercise.lines = "20", 
            eval = "T"), engine = "r")), code_check = structure(c("grade_code()", 
    "#Block 12", "#Distractors are blocks 9 and 11", "#You might explore tests of association here. These allow us to investigate associations between categories (e.g., between tweet-source, and tweet-emotion incidence)"
    ), chunk_opts = list(label = "props-code-check", eval = FALSE, 
        include = FALSE)), error_check = NULL, check = NULL, 
    solution = NULL, test_cases = NULL, options = list(eval = TRUE, 
        echo = TRUE, results = "markup", tidy = FALSE, tidy.opts = NULL, 
        collapse = FALSE, prompt = FALSE, comment = NA, highlight = FALSE, 
        size = "normalsize", background = "#F7F7F7", strip.white = TRUE, 
        cache = 3, cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "props", exercise = TRUE, exercise.lines = 20, 
        code = c("################### BLOCK 9 ########################", 
        "# Scatterplot", "trump_tweets %>%", "  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources", 
        "  mutate(senti_score = recode(sentiment_nrc, \"negative\" = 1, \"anger\" = 2, \"disgust\" = 3, \"fear\" = 4, \"sadness\" = 5, \"surprise\" = 6, \"anticipation\" = 7, \"trust\" = 8, \"joy\" = 9, \"positive\" = 10)) %>%", 
        "  ggplot(aes(x = senti_score, y = retweet_count)) +", 
        "  geom_point(shape = 1) +", "  theme(axis.text.x = element_text(angle = 90)) + ", 
        "  facet_grid( ~ source)", "# \\\\n", "#A correlation plot", 
        "trump_tweets %>%", "    filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources", 
        "  mutate(senti_score = recode(sentiment_nrc, \"negative\" = 1, \"anger\" = 2, \"disgust\" = 3, \"fear\" = 4, \"sadness\" = 5, \"surprise\" = 6, \"anticipation\" = 7, \"trust\" = 8, \"joy\" = 9, \"positive\" = 10)) %>%", 
        "  select(retweet_count,senti_score) %>%", "  na.omit() %>%", 
        "  cor() %>%", "  corrplot()", ""), out.width.px = 768, 
        out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/props_c08dd568534218fc4d0abb97ea7d7e5a", 
        params.src = "props, exercise = TRUE, exercise.lines=20, eval = T", 
        fig.alt = NULL, fig.num = 2, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-props-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-props-1-code-editor`)), session)
output$`tutorial-exercise-props-1-output` <- renderUI({
  `tutorial-exercise-props-1-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "props-1", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "props-1", code = "################### BLOCK 11 ########################\n# Stacked\ntrump_tweets %>% \n  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources)\n  ggplot(aes(x=source, y=sentiment_nrc, fill=sentiment_nrc)) + \n    geom_bar(position=\"stack\", stat=\"identity\") +\n    theme(axis.text.x = element_text(angle = 90))\n", 
        opts = list(label = "\"props-1\"", exercise = "TRUE", 
            exercise.lines = "20", eval = "T"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    test_cases = NULL, options = list(eval = TRUE, echo = TRUE, 
        results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, 
        prompt = FALSE, comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "props-1", exercise = TRUE, exercise.lines = 20, 
        code = c("################### BLOCK 11 ########################", 
        "# Stacked", "trump_tweets %>% ", "  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources)", 
        "  ggplot(aes(x=source, y=sentiment_nrc, fill=sentiment_nrc)) + ", 
        "    geom_bar(position=\"stack\", stat=\"identity\") +", 
        "    theme(axis.text.x = element_text(angle = 90))", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/props-1_47491bc37ce72f269e6bea17803fda76", 
        params.src = "props-1, exercise = TRUE, exercise.lines=20, eval = T", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-props-2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-props-2-code-editor`)), session)
output$`tutorial-exercise-props-2-output` <- renderUI({
  `tutorial-exercise-props-2-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "props-2", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "props-2", code = "################### BLOCK 12 ########################\n# Stacked + percent - You might decide to remove tweetdeck too given it's a much smaller sample\ntrump_tweets %>% \n  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources)\n  mutate(sentiment_nrc = factor(sentiment_nrc, levels=c(\"negative\", \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\",  \"joy\", \"trust\", \"anticipation\", \"positive\"))) %>%\nggplot(aes(x=source)) + \n    geom_bar(aes(fill=sentiment_nrc), position=\"fill\") + \n  theme(axis.text.x = element_text(angle = 90)) + \n  scale_fill_manual(values = c(\"negative\" = \"#D55E00\",\n                               \"anger\" = \"#CC79A7\", \n                               \"disgust\" = \"#E69F00\", \n                               \"fear\" = \"#F0E442\", \n                               \"sadness\" = \"red\", \n                               \"surprise\" = \"#999999\",\n                               \"positive\" = \"#009E73\", \n                               \"anticipation\" = \"#56B4E9\", \n                               \"trust\" = \"green\", \n                               \"joy\" = \"#0072B2\")\n                    )\n#attempt to use palettes that are visible to those with colour blindness. This palette should be ok.  Two biggest groups are ordered (by the mutate statement) so you can read from the bottom or the top. \n#trust, joy, anticipation, all intersect with positive \n#anger, disgust, fear, sadness all intersect with negative\n#surprise is sometimes positive or negative with interactive https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm\n", 
        opts = list(label = "\"props-2\"", exercise = "TRUE", 
            exercise.lines = "47", eval = "T"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    test_cases = NULL, options = list(eval = TRUE, echo = TRUE, 
        results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, 
        prompt = FALSE, comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "props-2", exercise = TRUE, exercise.lines = 47, 
        code = c("################### BLOCK 12 ########################", 
        "# Stacked + percent - You might decide to remove tweetdeck too given it's a much smaller sample", 
        "trump_tweets %>% ", "  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources)", 
        "  mutate(sentiment_nrc = factor(sentiment_nrc, levels=c(\"negative\", \"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\",  \"joy\", \"trust\", \"anticipation\", \"positive\"))) %>%", 
        "ggplot(aes(x=source)) + ", "    geom_bar(aes(fill=sentiment_nrc), position=\"fill\") + ", 
        "  theme(axis.text.x = element_text(angle = 90)) + ", 
        "  scale_fill_manual(values = c(\"negative\" = \"#D55E00\",", 
        "                               \"anger\" = \"#CC79A7\", ", 
        "                               \"disgust\" = \"#E69F00\", ", 
        "                               \"fear\" = \"#F0E442\", ", 
        "                               \"sadness\" = \"red\", ", 
        "                               \"surprise\" = \"#999999\",", 
        "                               \"positive\" = \"#009E73\", ", 
        "                               \"anticipation\" = \"#56B4E9\", ", 
        "                               \"trust\" = \"green\", ", 
        "                               \"joy\" = \"#0072B2\")", 
        "                    )", "#attempt to use palettes that are visible to those with colour blindness. This palette should be ok.  Two biggest groups are ordered (by the mutate statement) so you can read from the bottom or the top. ", 
        "#trust, joy, anticipation, all intersect with positive ", 
        "#anger, disgust, fear, sadness all intersect with negative", 
        "#surprise is sometimes positive or negative with interactive https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/props-2_76195d5c04bcc16d2e9734c0ab3ac953", 
        params.src = "props-2, exercise = TRUE, exercise.lines=47, eval = T", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "association-sol", 
    question = structure("How are NRC sentiment, source, and RTs associated?", html = TRUE, class = c("html", 
    "character")), answers = list(structure(list(id = "lnr_ans_6c5a483", 
        option = "Block 4, 10, 9 - these are definitely incorrect answers", 
        value = "Block 4, 10, 9 - these are definitely incorrect answers", 
        label = structure("Block 4, 10, 9 - these are definitely incorrect answers", html = TRUE, class = c("html", 
        "character")), correct = FALSE, message = structure("That&#39;s right!  There are ways you could explore this more, but crucially you should consider why you&#39;re conducting any particular analysis, and what your rationale is for treating the data the way you have. For example, does it really make sense to treat the emotion data as an interval level numeric variable for a correlation? (It seems to me to be at most ordinal, but likely nominal level data). You can see a couple of other insights here.", html = TRUE, class = c("html", 
        "character")), type = "literal"), class = c("tutorial_question_answer", 
    "tutorial_quiz_answer")), structure(list(id = "lnr_ans_a670ba3", 
        option = "Don't do this! (block 3)", value = "Don't do this! (block 3)", 
        label = structure("Don&#39;t do this! (block 3)", html = TRUE, class = c("html", 
        "character")), correct = TRUE, message = structure("That&#39;s right!  There are ways you could explore this more, but crucially you should consider why you&#39;re conducting any particular analysis, and what your rationale is for treating the data the way you have. For example, does it really make sense to treat the emotion data as an interval level numeric variable for a correlation? (It seems to me to be at most ordinal, but likely nominal level data). You can see a couple of other insights here.", html = TRUE, class = c("html", 
        "character")), type = "literal"), class = c("tutorial_question_answer", 
    "tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
    "character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
    "character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", 
    "character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
    "character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
    "character")), message = NULL, post_message = NULL), ids = list(
        answer = "association-sol-answer", question = "association-sol"), 
    loading = structure("<strong>Loading:<\u002fstrong> \nHow are NRC sentiment, source, and RTs associated?\n<br/><br/><br/>", html = TRUE, class = c("html", 
    "character")), random_answer_order = FALSE, allow_retry = FALSE, 
    seed = 2045064573.04769, options = list()), class = c("learnr_radio", 
"tutorial_question")), session = session)
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-association-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-association-code-editor`)), session)
output$`tutorial-exercise-association-output` <- renderUI({
  `tutorial-exercise-association-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "association", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "association", code = "################### BLOCK 9 ########################\n# Scatterplot\ntrump_tweets %>%\n  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources\n  mutate(senti_score = recode(sentiment_nrc, \"negative\" = 1, \"anger\" = 2, \"disgust\" = 3, \"fear\" = 4, \"sadness\" = 5, \"surprise\" = 6, \"anticipation\" = 7, \"trust\" = 8, \"joy\" = 9, \"positive\" = 10)) %>%\n  ggplot(aes(x = senti_score, y = retweet_count)) +\n  geom_point(shape = 1) +\n  theme(axis.text.x = element_text(angle = 90)) + \n  facet_grid( ~ source)\n#A correlation plot\ntrump_tweets %>%\n    filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources\n  mutate(senti_score = recode(sentiment_nrc, \"negative\" = 1, \"anger\" = 2, \"disgust\" = 3, \"fear\" = 4, \"sadness\" = 5, \"surprise\" = 6, \"anticipation\" = 7, \"trust\" = 8, \"joy\" = 9, \"positive\" = 10)) %>%\n  select(retweet_count,senti_score) %>%\n  na.omit() %>%\n  cor() %>%\n  corrplot()\n", 
        opts = list(label = "\"association\"", exercise = "TRUE", 
            exercise.lines = "21", eval = "T"), engine = "r")), 
    code_check = structure(c("grade_this_code(", "  correct = \"That's right!  There are ways you could explore this more, but crucially you should consider why you're conducting any particular analysis, and what your rationale is for treating the data the way you have. For example, does it really make sense to treat the emotion data as an interval level numeric variable for a correlation? (It seems to me to be at most ordinal, but likely nominal level data). You can see a couple of other insights here \")", 
    "", "#Block 3 (which is blank)", "#Distractors are a bunch of boxplots in block 10, heatmap block 4, and scatterplot + corplot block 9", 
    "#on feedback note the below", "#Boxplots by source and sentiment ", 
    ""), chunk_opts = list(label = "association-code-check", 
        eval = FALSE, include = FALSE)), error_check = NULL, 
    check = NULL, solution = NULL, test_cases = NULL, options = list(
        eval = TRUE, echo = TRUE, results = "markup", tidy = FALSE, 
        tidy.opts = NULL, collapse = FALSE, prompt = FALSE, comment = NA, 
        highlight = FALSE, size = "normalsize", background = "#F7F7F7", 
        strip.white = TRUE, cache = 3, cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "association", exercise = TRUE, exercise.lines = 21, 
        code = c("################### BLOCK 9 ########################", 
        "# Scatterplot", "trump_tweets %>%", "  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources", 
        "  mutate(senti_score = recode(sentiment_nrc, \"negative\" = 1, \"anger\" = 2, \"disgust\" = 3, \"fear\" = 4, \"sadness\" = 5, \"surprise\" = 6, \"anticipation\" = 7, \"trust\" = 8, \"joy\" = 9, \"positive\" = 10)) %>%", 
        "  ggplot(aes(x = senti_score, y = retweet_count)) +", 
        "  geom_point(shape = 1) +", "  theme(axis.text.x = element_text(angle = 90)) + ", 
        "  facet_grid( ~ source)", "#A correlation plot", "trump_tweets %>%", 
        "    filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources", 
        "  mutate(senti_score = recode(sentiment_nrc, \"negative\" = 1, \"anger\" = 2, \"disgust\" = 3, \"fear\" = 4, \"sadness\" = 5, \"surprise\" = 6, \"anticipation\" = 7, \"trust\" = 8, \"joy\" = 9, \"positive\" = 10)) %>%", 
        "  select(retweet_count,senti_score) %>%", "  na.omit() %>%", 
        "  cor() %>%", "  corrplot()", ""), out.width.px = 768, 
        out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/association_f5649d10c0dce01453be1ad7f3b1670a", 
        params.src = "association, exercise = TRUE, exercise.lines=21, eval = T", 
        fig.alt = NULL, fig.num = 2, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-association-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-association-1-code-editor`)), session)
output$`tutorial-exercise-association-1-output` <- renderUI({
  `tutorial-exercise-association-1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "association-1", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "association-1", code = "################### BLOCK 3 ########################\nprint(\"I am a blank chunk\")\n#Sometimes, the best way to address a question at this stage of the investigation is to break it down\n#In this case, you've looked at sentiment by source, and you've looked at RTs by source.\n#You could also look at RT by source, to investigate at a descriptive level\n#(There's some sample code to do that in the feedback - it shows there's not much difference probably)\n#But, at this stage you're getting into the need to do different kinds of analysis, but there's still more value to get from sticking to descriptives.\n#To use this block, copy all this commented text\n", 
        opts = list(label = "\"association-1\"", exercise = "TRUE", 
            exercise.lines = "21", eval = "T"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    test_cases = NULL, options = list(eval = TRUE, echo = TRUE, 
        results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, 
        prompt = FALSE, comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "association-1", exercise = TRUE, exercise.lines = 21, 
        code = c("################### BLOCK 3 ########################", 
        "print(\"I am a blank chunk\")", "#Sometimes, the best way to address a question at this stage of the investigation is to break it down", 
        "#In this case, you've looked at sentiment by source, and you've looked at RTs by source.", 
        "#You could also look at RT by source, to investigate at a descriptive level", 
        "#(There's some sample code to do that in the feedback - it shows there's not much difference probably)", 
        "#But, at this stage you're getting into the need to do different kinds of analysis, but there's still more value to get from sticking to descriptives.", 
        "#To use this block, copy all this commented text", ""
        ), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/association-1_389bc46c36294ef065df04798912d477", 
        params.src = "association-1, exercise = TRUE, exercise.lines=21, eval = T", 
        fig.alt = NULL, fig.num = 0, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-association-2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-association-2-code-editor`)), session)
output$`tutorial-exercise-association-2-output` <- renderUI({
  `tutorial-exercise-association-2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "association-2", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "association-2", code = "################### BLOCK 10 ########################\n#Boxplots by source and sentiment \ntrump_tweets %>% \n  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources\n  ggplot(aes(x = factor(sentiment_nrc), y = retweet_count)) + \n  geom_boxplot() +\n  stat_summary(\n    fun = mean, geom=\"point\", shape=5, size=4) +\n  facet_grid(. ~ source) +\n  theme(axis.text.x = element_text(angle = 90))\n", 
        opts = list(label = "\"association-2\"", exercise = "TRUE", 
            exercise.lines = "41", eval = "T"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    test_cases = NULL, options = list(eval = TRUE, echo = TRUE, 
        results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, 
        prompt = FALSE, comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "association-2", exercise = TRUE, exercise.lines = 41, 
        code = c("################### BLOCK 10 ########################", 
        "#Boxplots by source and sentiment ", "trump_tweets %>% ", 
        "  filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>% #filter to the  biggest sources", 
        "  ggplot(aes(x = factor(sentiment_nrc), y = retweet_count)) + ", 
        "  geom_boxplot() +", "  stat_summary(", "    fun = mean, geom=\"point\", shape=5, size=4) +", 
        "  facet_grid(. ~ source) +", "  theme(axis.text.x = element_text(angle = 90))", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/association-2_22a40afeac9d7dd591b0684b923a26e1", 
        params.src = "association-2, exercise = TRUE, exercise.lines=41, eval = T", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-association-3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-association-3-code-editor`)), session)
output$`tutorial-exercise-association-3-output` <- renderUI({
  `tutorial-exercise-association-3-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "association-3", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "association-3", code = "################### BLOCK 4 ########################\n#You can have this one for free - heatmaps can be useful sometimes, but not like this. \n#trump_tweets %>% mutate(reply_to = ifelse(in_reply_to_user_id_str > 0, \"Y\", \"N\")) %>% \ntrump_tweets %>% filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>%\n  ggplot(aes(x = sentiment_nrc, source)) +\n  geom_tile(aes(fill = retweet_count)) +\n  theme(axis.text.x = element_text(angle = 90))\n", 
        opts = list(label = "\"association-3\"", exercise = "TRUE", 
            exercise.lines = "41", eval = "T"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    test_cases = NULL, options = list(eval = TRUE, echo = TRUE, 
        results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, 
        prompt = FALSE, comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "association-3", exercise = TRUE, exercise.lines = 41, 
        code = c("################### BLOCK 4 ########################", 
        "#You can have this one for free - heatmaps can be useful sometimes, but not like this. ", 
        "#trump_tweets %>% mutate(reply_to = ifelse(in_reply_to_user_id_str > 0, \"Y\", \"N\")) %>% ", 
        "trump_tweets %>% filter(source %in% c(\"Twitter for Android\",\"Twitter for iPhone\",\"TweetDeck\",\"Twitter Web Client\")) %>%", 
        "  ggplot(aes(x = sentiment_nrc, source)) +", "  geom_tile(aes(fill = retweet_count)) +", 
        "  theme(axis.text.x = element_text(angle = 90))", ""
        ), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/association-3_e70fad7ef4cd4f4b69d663d064dab909", 
        params.src = "association-3, exercise = TRUE, exercise.lines=41, eval = T", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "words-sol", question = structure("What kind of language do Trump&#39;s tweets use?", html = TRUE, class = c("html", 
"character")), answers = list(structure(list(id = "lnr_ans_178d050", 
    option = "Block 15", value = "Block 15", label = structure("Block 15", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = structure("You can see in Block 16 how a very simple approach - wordclouds - can provide useful insight, but how easy it is to be distracted by (1) unnecessary use of colour, shape, and size; and (2) how you can use the approach to actually gain insight e.g. through comparison. There are more sophisticated approaches (see the tidytext package for some nice tutorials). You should also consider if you&#39;re looking at unigrams (1 word) or if expressions (ngrams) or word-pairs (bigrams) are important. And whether your data is stemmed (stem, stemming, stemmed all treated same), or not.", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_9b89bc", 
    option = "Block 16", value = "Block 16", label = structure("Block 16", html = TRUE, class = c("html", 
    "character")), correct = TRUE, message = structure("You can see in Block 16 how a very simple approach - wordclouds - can provide useful insight, but how easy it is to be distracted by (1) unnecessary use of colour, shape, and size; and (2) how you can use the approach to actually gain insight e.g. through comparison. There are more sophisticated approaches (see the tidytext package for some nice tutorials). You should also consider if you&#39;re looking at unigrams (1 word) or if expressions (ngrams) or word-pairs (bigrams) are important. And whether your data is stemmed (stem, stemming, stemmed all treated same), or not.", html = TRUE, class = c("html", 
    "character")), type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
"character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
"character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", 
"character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
"character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
"character")), message = NULL, post_message = NULL), ids = list(
    answer = "words-sol-answer", question = "words-sol"), loading = structure("<strong>Loading:<\u002fstrong> \nWhat kind of language do Trump&#39;s tweets use?\n<br/><br/><br/>", html = TRUE, class = c("html", 
"character")), random_answer_order = FALSE, allow_retry = FALSE, 
    seed = 315770296.352958, options = list()), class = c("learnr_radio", 
"tutorial_question")), session = session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-words-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-words-code-editor`)), session)
output$`tutorial-exercise-words-output` <- renderUI({
  `tutorial-exercise-words-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "words", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "words", code = "################### BLOCK 15 ########################\nwc <- tweet_words %>%\n  anti_join(stop_words) %>%\n  count(word) %>%\n  slice_max(n, n = 500)\nggwordcloud2(wc, color = \"random-dark\", shape = \"star\")\n", 
        opts = list(label = "\"words\"", exercise = "TRUE", exercise.lines = "11", 
            eval = "T"), engine = "r")), code_check = structure(c("grade_code()", 
    "#Correct is block 16, distractor 15", ""), chunk_opts = list(
        label = "words-code-check", eval = FALSE, include = FALSE)), 
    error_check = NULL, check = NULL, solution = NULL, test_cases = NULL, 
    options = list(eval = TRUE, echo = TRUE, results = "markup", 
        tidy = FALSE, tidy.opts = NULL, collapse = FALSE, prompt = FALSE, 
        comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "words", exercise = TRUE, exercise.lines = 11, 
        code = c("################### BLOCK 15 ########################", 
        "wc <- tweet_words %>%", "  anti_join(stop_words) %>%", 
        "  count(word) %>%", "  slice_max(n, n = 500)", "ggwordcloud2(wc, color = \"random-dark\", shape = \"star\")", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/words_a1694076d60d7f3b255f579bec39adb4", 
        params.src = "words, exercise = TRUE, exercise.lines=11, eval = T", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-words-1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-words-1-code-editor`)), session)
output$`tutorial-exercise-words-1-output` <- renderUI({
  `tutorial-exercise-words-1-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::store_exercise_cache(structure(list(label = "words-1", global_setup = structure(c("#tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.", 
"#It would be sensible to also include RAppArmor", "library(learnr)", 
"library(gradethis)", "", "gradethis::gradethis_setup()", "tutorial_options(exercise.checker = gradethis::grade_learnr, exercise.eval=T, exercise.reveal_solution = T)", 
"", "knitr::opts_chunk$set(", "\tfig.height = 6,", "\tfig.width = 8,", 
"\twarning = FALSE,", "\tcache = TRUE", ")", "", "tut_reptitle <- \"matchR\"", 
"", "###############################", "###############################", 
"##############################", "#install.packages(c(\"psych\",\"ggplot2\",\"doBy\",\"reshape2\",\"knitr\",\"lattice\"))", 
"  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries", 
"  sh(library(ggplot2))  #for graphs and plots", "  sh(library(psych))    #for statistical measures and testing", 
"  #sh(library(doBy))     #for group by analysis dplyr covers this", 
"  #sh(library(reshape2)) #for data wrangling", "  sh(library(knitr))    #for rendering markdown", 
"  #sh(library(lattice))  #just to illustrate another histogram function ", 
"  library(dslabs)", "  library(shiny) #shouldn't be necessary but...", 
" # install.packages(\"remotes\")", "  #remotes::install_github(\"rstudio-education/gradethis\")", 
"", "  library(textdata)", "  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep ", 
"  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too", 
"  #library(wordcloud2) #This may not work well when knitted", 
"  library(kableExtra)", "  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score ", 
"  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object", 
"  #this is great! https://github.com/trinker/sentimentr#examples", 
"  library(tidyverse)", "  library(tidytext)", "  library(corrplot)", 
"#detach(package:plyr)", "", "#library(rsconnect)", "#deployApp(appName = \"Snippet_matchR)", 
"##############################################################", 
"#############LOAD DATA HERE######################################", 
"##############################################################", 
"", "if(!file.exists(\"matchr.RData\")) {", "  ", "#trump_tweets <- data(\"trump_tweets\")", 
"data(\"trump_tweets\")", "##############AND we're going to do some tidying up #############", 
"", "links <- \"https://t.co/[A-Za-z\\\\d]+|&amp;\" #regex to get rid of picture links", 
"tweet_words <- trump_tweets %>% ", "  mutate(text = str_replace_all(text, links, \"\"))  %>%", 
"  unnest_tokens(word, text, token = \"tweets\") %>%", "  filter(!word %in% stop_words$word &", 
"           !str_detect(word, \"^\\\\d+$\")) %>%", "  mutate(word = str_replace(word, \"^'\", \"\"))", 
"", "##############And add sentiment analysis columns for later #########", 
"bing <- get_sentiments(\"bing\")", "afinn <- get_sentiments(\"afinn\")", 
"", "#loughran <- get_sentiments(\"loughran\") %>% count(sentiment)", 
"#get_sentiments(\"nrc\") %>% count(sentiment) ", "", "nrc <- get_sentiments(\"nrc\") %>%", 
"  select(word, sentiment)", "", "#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.", 
"", "trump_tweets %<>% ", "  dplyr::mutate(sent_split = get_sentences(text)) %>%", 
"  dplyr::mutate(sentiment_by(sent_split)) %>%", "  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, \"Negative\",", 
"                           ifelse(ave_sentiment > 0.2, \"Positive\",\"Neutral\")))", 
"", "", "tt_senti2 <- tweet_words %>%", "  inner_join(get_sentiments(\"afinn\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_afinn = mean(value)) ", 
"", "#mode <- function(codes){which.max(tabulate(codes))}", "mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below", 
"", "tt_senti3 <- tweet_words %>%", "  inner_join(get_sentiments(\"nrc\")) %>%", 
"  group_by(id_str) %>%", "  dplyr::summarise(sentiment_nrc = mode(sentiment))", 
"                ", "#join the sentiment to the original twitter data", 
"#trump_tweets <- left_join(trump_tweets, tt_senti, by = c(\"id_str\" = \"index\")) ", 
"trump_tweets <- left_join(trump_tweets, tt_senti2, by = \"id_str\") ", 
"trump_tweets <- left_join(trump_tweets, tt_senti3, by = \"id_str\") ", 
"", "#write_csv(trump_tweets,\"trump_tweets.csv\")", "#write_csv(tweet_words,\"tweet_words.csv\")", 
"save(trump_tweets,tweet_words, file = \"matchr.RData\")", "", 
"rm(tt_senti2,tt_senti3)", "", "} else {", "  #trump_tweets <- read_csv(\"trump_tweets.csv\")", 
"  #tweet_words <- read_csv(tweet_words,\"tweet_words.csv\")", 
"  load(\"matchr.RData\")", "}", "#table(tweet_words %>% inner_join(get_sentiments(\"nrc\")) %>% select(sentiment)) ", 
"#afinn is also pretty cool", ""), chunk_opts = list(label = "setup", 
    include = FALSE, warning = F, message = F)), setup = NULL, 
    chunks = list(list(label = "words-1", code = "################### BLOCK 16 ########################\n#wordcloud2(wc, color = \"black\", maxRotation = 0, minRotation = 0, shape = \"diamond\") #diamond is just a square\n#wordcloud - different package - makes simple ones too, and has an inbuilt function for comparison.  We'll do that for 2 groups positive and negative words (but you could use more)\ntweet_words %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  reshape2::acast(word ~ sentiment, value.var = \"n\", fill = 0) %>%  #ideally rewrite using spread from dplyr\n  comparison.cloud(term.matrix = ., \n                   colors = c(\"grey20\", \"grey80\"),\n                   max.words = 100,\n                   rot.per = 0)\n", 
        opts = list(label = "\"words-1\"", exercise = "TRUE", 
            exercise.lines = "21", eval = "T"), engine = "r")), 
    code_check = NULL, error_check = NULL, check = NULL, solution = NULL, 
    test_cases = NULL, options = list(eval = TRUE, echo = TRUE, 
        results = "markup", tidy = FALSE, tidy.opts = NULL, collapse = FALSE, 
        prompt = FALSE, comment = NA, highlight = FALSE, size = "normalsize", 
        background = "#F7F7F7", strip.white = TRUE, cache = 3, 
        cache.path = "snippet_matchR_clustered_quizy_cache/html/", 
        cache.vars = NULL, cache.lazy = TRUE, dependson = NULL, 
        autodep = FALSE, cache.rebuild = FALSE, fig.keep = "high", 
        fig.show = "asis", fig.align = "default", fig.path = "snippet_matchR_clustered_quizy_files/figure-html/", 
        dev = "png", dev.args = NULL, dpi = 192, fig.ext = "png", 
        fig.width = 8, fig.height = 6, fig.env = "figure", fig.cap = NULL, 
        fig.scap = NULL, fig.lp = "fig:", fig.subcap = NULL, 
        fig.pos = "", out.width = 768, out.height = NULL, out.extra = NULL, 
        fig.retina = 2, external = TRUE, sanitize = FALSE, interval = 1, 
        aniopts = "controls,loop", warning = FALSE, error = FALSE, 
        message = TRUE, render = NULL, ref.label = NULL, child = NULL, 
        engine = "r", split = FALSE, include = TRUE, purl = TRUE, 
        max.print = 1000, exercise.timelimit = 60, exercise.checker = "function (...) \n{\n    lifecycle::deprecate_soft(\"0.2.2\", \"grade_learnr()\", \"gradethis_exercise_checker()\")\n    gradethis_exercise_checker(...)\n}", 
        exercise.error.check.code = "gradethis_error_checker()", 
        exercise.eval = TRUE, exercise.reveal_solution = TRUE, 
        label = "words-1", exercise = TRUE, exercise.lines = 21, 
        code = c("################### BLOCK 16 ########################", 
        "#wordcloud2(wc, color = \"black\", maxRotation = 0, minRotation = 0, shape = \"diamond\") #diamond is just a square", 
        "#wordcloud - different package - makes simple ones too, and has an inbuilt function for comparison.  We'll do that for 2 groups positive and negative words (but you could use more)", 
        "tweet_words %>%", "  inner_join(get_sentiments(\"bing\")) %>%", 
        "  count(word, sentiment, sort = TRUE) %>%", "  reshape2::acast(word ~ sentiment, value.var = \"n\", fill = 0) %>%  #ideally rewrite using spread from dplyr", 
        "  comparison.cloud(term.matrix = ., ", "                   colors = c(\"grey20\", \"grey80\"),", 
        "                   max.words = 100,", "                   rot.per = 0)", 
        ""), out.width.px = 768, out.height.px = 576, hash = "snippet_matchR_clustered_quizy_cache/html/words-1_3777573ce9ec62b51d45bedefb88aa9f", 
        params.src = "words-1, exercise = TRUE, exercise.lines=21, eval = T", 
        fig.alt = NULL, fig.num = 1, exercise.df_print = "paged"), 
    engine = "r"), class = "tutorial_exercise"))
</script>
</p>
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["i18n"]},{"type":"character","attributes":{},"value":["21.6.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/i18n"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["i18next.min.js","tutorial-i18n-init.js"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["<script id=\"i18n-cstm-trns\" type=\"application/json\">{\"language\":\"en\",\"resources\":{\"en\":{\"translation\":{\"button\":{\"runcode\":\"Run Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Hint\",\"hint_plural\":\"Hints\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Next Hint\",\"hintprev\":\"Previous Hint\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copy to Clipboard\",\"startover\":\"Start Over\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continue\",\"submitanswer\":\"Submit Answer\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Previous Topic\",\"nexttopic\":\"Next Topic\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Try Again\"},\"text\":{\"startover\":\"Start Over\",\"areyousure\":\"Are you sure you want to start over? (all exercise progress will be reset)\",\"youmustcomplete\":\"You must complete the\",\"exercise\":\"exercise\",\"exercise_plural\":\"exercises\",\"inthissection\":\"in this section before continuing.\",\"code\":\"Code\",\"enginecap\":\"{{engine}} $t(text.code)\",\"quiz\":\"Quiz\",\"blank\":\"blank\",\"blank_plural\":\"blanks\",\"exercisecontainsblank\":\"This exercise contains {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Please replace {{blank}} with valid code.\",\"unparsable\":\"It looks like this might not be valid R code. R cannot determine how to turn your text into a complete command. You may have forgotten to fill in a blank, to remove an underscore, to include a comma between arguments, or to close an opening <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> or <code>{<\\/code> with a matching <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> or <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>It looks like your R code contains specially formatted quotation marks or &quot;curly&quot; quotes (<code>{{character}}<\\/code>) around character strings, making your code invalid. R requires character values to be contained in straight quotation marks (<code>&quot;<\\/code> or <code>'<\\/code>).<\\/p> {{code}} <p>Don't worry, this is a common source of errors when you copy code from another app that applies its own formatting to text. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. Try deleting the special character from your code and retyping it manually.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"and\":\"and\",\"or\":\"or\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"fr\":{\"translation\":{\"button\":{\"runcode\":\"Lancer le Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Indication\",\"hint_plural\":\"Indications\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Indication Suivante\",\"hintprev\":\"Indication Précédente\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copier dans le Presse-papier\",\"startover\":\"Recommencer\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuer\",\"submitanswer\":\"Soumettre\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Chapitre Précédent\",\"nexttopic\":\"Chapitre Suivant\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Réessayer\"},\"text\":{\"startover\":\"Recommencer\",\"areyousure\":\"Êtes-vous certains de vouloir recommencer? (La progression sera remise à zéro)\",\"youmustcomplete\":\"Vous devez d'abord compléter\",\"exercise\":\"l'exercice\",\"exercise_plural\":\"des exercices\",\"inthissection\":\"de cette section avec de continuer.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"et\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"es\":{\"translation\":{\"button\":{\"runcode\":\"Ejecutar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Pista\",\"hint_plural\":\"Pistas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Siguiente pista\",\"hintprev\":\"Pista anterior\",\"solution\":\"Solución\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar al portapapeles\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar respuesta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tema anterior\",\"nexttopic\":\"Tema siguiente\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Volver a intentar\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"¿De verdad quieres empezar de nuevo? (todo el progreso del ejercicio se perderá)\",\"youmustcomplete\":\"Debes completar\",\"exercise\":\"el ejercicio\",\"exercise_plural\":\"los ejercicios\",\"inthissection\":\"en esta sección antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Cuestionario\",\"and\":\"y\",\"or\":\"o\",\"oxfordcomma\":\"\"}}},\"pt\":{\"translation\":{\"button\":{\"runcode\":\"Executar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Dica\",\"hint_plural\":\"Dicas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Próxima dica\",\"hintprev\":\"Dica anterior\",\"solution\":\"Solução\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar para a área de transferência\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar resposta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tópico anterior\",\"nexttopic\":\"Próximo tópico\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tentar novamente\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"Tem certeza que deseja começar novamente? (todo o progresso feito será perdido)\",\"youmustcomplete\":\"Você deve completar\",\"exercise\":\"o exercício\",\"exercise_plural\":\"os exercícios\",\"inthissection\":\"nesta seção antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"e\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"tr\":{\"translation\":{\"button\":{\"runcode\":\"Çalistirma Kodu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Ipucu\",\"hint_plural\":\"Ipuçlari\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Sonraki Ipucu\",\"hintprev\":\"Önceki Ipucu\",\"solution\":\"Çözüm\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Pano'ya Kopyala\",\"startover\":\"Bastan Baslamak\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Devam et\",\"submitanswer\":\"Cevabi onayla\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Önceki Konu\",\"nexttopic\":\"Sonraki Konu\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tekrar Deneyin\"},\"text\":{\"startover\":\"Bastan Baslamak\",\"areyousure\":\"Bastan baslamak istediginizden emin misiniz? (tüm egzersiz ilerlemesi kaybolacak)\",\"youmustcomplete\":\"Tamamlamalisin\",\"exercise\":\"egzersiz\",\"exercise_plural\":\"egzersizler\",\"inthissection\":\"devam etmeden önce bu bölümde\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Sinav\",\"oxfordcomma\":\"\"}}},\"emo\":{\"translation\":{\"button\":{\"runcode\":\"<U+0001F3C3>\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"<U+0001F4A1>\",\"hint_plural\":\"$t(button.hint)\",\"hinttitle\":\"$t(button.hint)\",\"solution\":\"<U+0001F3AF>\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"<U+0001F4CB>\",\"startover\":\"<U+23EE>\",\"startovertitle\":\"Start Over\",\"continue\":\"<U+2705>\",\"submitanswer\":\"<U+0001F197>\",\"submitanswertitle\":\"Submit Answer\",\"previoustopic\":\"<U+2B05>\",\"nexttopic\":\"<U+27A1>\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"<U+0001F501>\"},\"text\":{\"startover\":\"<U+23EE>\",\"areyousure\":\"<U+0001F914>\",\"youmustcomplete\":\"<U+26A0><U+FE0F> <U+0001F449> <U+0001F9D1><U+200D><U+0001F4BB>\",\"exercise\":\"\",\"exercise_plural\":\"\",\"inthissection\":\"\",\"code\":\"<U+0001F4BB>\",\"enginecap\":\"$t(text.code) {{engine}}\",\"oxfordcomma\":\"\"}}},\"eu\":{\"translation\":{\"button\":{\"runcode\":\"Kodea egikaritu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Laguntza\",\"hint_plural\":\"Laguntza\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Aurreko laguntza\",\"hintprev\":\"Hurrengo laguntza\",\"solution\":\"Ebazpena\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Arbelean kopiatu\",\"startover\":\"Berrabiarazi\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Jarraitu\",\"submitanswer\":\"Erantzuna bidali\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Aurreko atala\",\"nexttopic\":\"Hurrengo atala\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Berriro saiatu\"},\"text\":{\"startover\":\"Berrabiarazi\",\"areyousure\":\"Berriro hasi nahi duzu? (egindako lana galdu egingo da)\",\"youmustcomplete\":\"Aurrera egin baino lehen atal honetako\",\"exercise\":\"ariketa egin behar duzu.\",\"exercise_plural\":\"ariketak egin behar dituzu.\",\"inthissection\":\"\",\"code\":\"Kodea\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Galdetegia\",\"oxfordcomma\":\"\"}}},\"de\":{\"translation\":{\"button\":{\"runcode\":\"Code ausführen\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Tipp\",\"hint_plural\":\"Tipps\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Nächster Tipp\",\"hintprev\":\"Vorheriger Tipp\",\"solution\":\"Lösung\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"In die Zwischenablage kopieren\",\"startover\":\"Neustart\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Weiter\",\"submitanswer\":\"Antwort einreichen\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Vorheriges Kapitel\",\"nexttopic\":\"Nächstes Kapitel\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Nochmal versuchen\"},\"text\":{\"startover\":\"Neustart\",\"areyousure\":\"Bist du sicher, dass du neustarten willst? (der gesamte Lernfortschritt wird gelöscht)\",\"youmustcomplete\":\"Vervollstädinge\",\"exercise\":\"die Übung\",\"exercise_plural\":\"die Übungen\",\"inthissection\":\"in diesem Kapitel, bevor du fortfährst.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"Lücke\",\"blank_plural\":\"Lücken\",\"pleasereplaceblank\":\"Bitte ersetze {{blank}} mit gültigem Code.\",\"unparsable\":\"Dies scheint kein gültiger R Code zu sein. R kann deinen Text nicht in einen gültigen Befehl übersetzen. Du hast vielleicht vergessen, die Lücke zu füllen, einen Unterstrich zu entfernen, ein Komma zwischen Argumente zu setzen oder ein eröffnendes <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> oder <code>{<\\/code> mit einem zugehörigen <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> oder <code>}<\\/code> zu schließen.\\n\",\"and\":\"und\",\"or\":\"oder\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"ko\":{\"translation\":{\"button\":{\"runcode\":\"<U+CF54><U+B4DC> <U+C2E4><U+D589>\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"<U+D78C><U+D2B8>\",\"hint_plural\":\"<U+D78C><U+D2B8><U+B4E4>\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"<U+B2E4><U+C74C> <U+D78C><U+D2B8>\",\"hintprev\":\"<U+C774><U+C804> <U+D78C><U+D2B8>\",\"solution\":\"<U+C194><U+B8E8><U+C158>\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"<U+D074><U+B9BD><U+BCF4><U+B4DC><U+C5D0> <U+BCF5><U+C0AC>\",\"startover\":\"<U+C7AC><U+D559><U+C2B5>\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"<U+B2E4><U+C74C> <U+D559><U+C2B5><U+C73C><U+B85C>\",\"submitanswer\":\"<U+C815><U+B2F5> <U+C81C><U+CD9C>\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"<U+C774><U+C804> <U+D1A0><U+D53D>\",\"nexttopic\":\"<U+B2E4><U+C74C> <U+D1A0><U+D53D>\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"<U+C7AC><U+C2DC><U+B3C4>\"},\"text\":{\"startover\":\"<U+C7AC><U+D559><U+C2B5>\",\"areyousure\":\"<U+B2E4><U+C2DC> <U+C2DC><U+C791> <U+D558><U+C2DC><U+ACA0><U+C2B5><U+B2C8><U+AE4C>? (<U+BAA8><U+B4E0> <U+C608><U+C81C><U+C758> <U+C9C4><U+D589> <U+C815><U+BCF4><U+AC00> <U+C7AC><U+C124><U+C815><U+B429><U+B2C8><U+B2E4>)\",\"youmustcomplete\":\"<U+B2F9><U+C2E0><U+C740> <U+C644><U+B8CC><U+D574><U+C57C> <U+D569><U+B2C8><U+B2E4>\",\"exercise\":\"<U+C5F0><U+C2B5><U+BB38><U+C81C>\",\"exercise_plural\":\"<U+C5F0><U+C2B5><U+BB38><U+C81C><U+B4E4>\",\"inthissection\":\"<U+C774> <U+C139><U+C158><U+C744> <U+C2E4><U+D589><U+D558><U+AE30> <U+C804><U+C5D0>\",\"code\":\"<U+CF54><U+B4DC>\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"<U+D034><U+C988>\",\"blank\":\"<U+ACF5><U+BC31>\",\"blank_plural\":\"<U+ACF5><U+BC31><U+B4E4>\",\"exercisecontainsblank\":\"<U+C774> <U+C5F0><U+C2B5><U+BB38><U+C81C><U+C5D0><U+B294> {{count}}<U+AC1C><U+C758> $t(text.blank)<U+C774> <U+D3EC><U+D568><U+B418><U+C5B4> <U+C788><U+C2B5><U+B2C8><U+B2E4>.\",\"pleasereplaceblank\":\"{{blank}}<U+B97C> <U+C720><U+D6A8><U+D55C> <U+CF54><U+B4DC><U+B85C> <U+BC14><U+AFB8><U+C2ED><U+C2DC><U+C624>.\",\"unparsable\":\"<U+C774><U+AC83><U+C740> <U+C720><U+D6A8><U+D55C> R <U+CF54><U+B4DC><U+AC00> <U+C544><U+B2D0> <U+C218> <U+C788><U+C2B5><U+B2C8><U+B2E4>. R<U+C740> <U+D14D><U+C2A4><U+D2B8><U+B97C> <U+C644><U+C804><U+D55C> <U+BA85><U+B839><U+C73C><U+B85C> <U+BCC0><U+D658><U+D558><U+B294> <U+BC29><U+BC95><U+C744> <U+ACB0><U+C815><U+D560> <U+C218> <U+C5C6><U+C2B5><U+B2C8><U+B2E4>. <U+B2F9><U+C2E0><U+C740> <U+ACF5><U+BC31><U+C774><U+B098> <U+BC11><U+C904><U+C744> <U+B300><U+CCB4><U+D558><U+C5EC> <U+CC44><U+C6B0><U+AE30>, <U+C778><U+C218><U+B97C> <U+CEF4><U+B9C8><U+B85C> <U+AD6C><U+BD84><U+D558><U+AE30>, <U+B610><U+B294> <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> , <code>{<\\/code><U+B85C> <U+C2DC><U+C791><U+D558><U+B294> <U+AD6C><U+BB38><U+C744> <U+B2EB><U+B294> <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>, <code>}<\\/code><U+C744> <U+C78A><U+C5C8><U+C744> <U+C218><U+B3C4> <U+C788><U+C2B5><U+B2C8><U+B2E4>.\\n\",\"and\":\"<U+ADF8><U+B9AC><U+ACE0>\",\"or\":\"<U+D639><U+C740>\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}},\"zh\":{\"translation\":{\"button\":{\"runcode\":\"<U+8FD0><U+884C><U+4EE3><U+7801>\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"<U+63D0><U+793A>\",\"hint_plural\":\"<U+63D0><U+793A>\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"<U+4E0B><U+4E00><U+4E2A><U+63D0><U+793A>\",\"hintprev\":\"<U+4E0A><U+4E00><U+4E2A><U+63D0><U+793A>\",\"solution\":\"<U+7B54><U+6848>\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"<U+590D><U+5236><U+5230><U+526A><U+5207><U+677F>\",\"startover\":\"<U+91CD><U+65B0><U+5F00><U+59CB>\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"<U+7EE7><U+7EED>\",\"submitanswer\":\"<U+63D0><U+4EA4><U+7B54><U+6848>\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"<U+4E0A><U+4E00><U+4E13><U+9898>\",\"nexttopic\":\"<U+4E0B><U+4E00><U+4E13><U+9898>\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"<U+518D><U+8BD5><U+4E00><U+6B21>\"},\"text\":{\"startover\":\"<U+91CD><U+7F6E>\",\"areyousure\":\"<U+4F60><U+786E><U+5B9A><U+8981><U+91CD><U+65B0><U+5F00><U+59CB><U+5417>? (<U+6240><U+6709><U+5F53><U+524D><U+8FDB><U+5EA6><U+5C06><U+88AB><U+91CD><U+7F6E>)\",\"youmustcomplete\":\"<U+4F60><U+5FC5><U+987B><U+5B8C><U+6210>\",\"exercise\":\"<U+7EC3><U+4E60>\",\"exercise_plural\":\"<U+7EC3><U+4E60>\",\"inthissection\":\"<U+5728><U+8FDB><U+884C><U+672C><U+8282><U+4E4B><U+524D>\",\"code\":\"<U+4EE3><U+7801>\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"<U+6D4B><U+8BD5>\",\"blank\":\"<U+7A7A>\",\"blank_plural\":\"<U+7A7A>\",\"exercisecontainsblank\":\"<U+672C><U+7EC3><U+4E60><U+5305><U+542B>{{count}}<U+4E2A>$t(text.blank)\",\"pleasereplaceblank\":\"<U+8BF7><U+5728>{{blank}}<U+5185><U+586B><U+5199><U+6070><U+5F53><U+7684><U+4EE3><U+7801>\",\"unparsable\":\"<U+8FD9><U+4F3C><U+4E4E><U+4E0D><U+662F><U+6709><U+6548><U+7684>R<U+4EE3><U+7801><U+3002> R<U+4E0D><U+77E5><U+9053><U+5982><U+4F55><U+5C06><U+60A8><U+7684><U+6587><U+672C><U+8F6C><U+6362><U+4E3A><U+5B8C><U+6574><U+7684><U+547D><U+4EE4><U+3002> <U+60A8><U+662F><U+5426><U+5FD8><U+4E86><U+586B><U+7A7A>,<U+5FD8><U+4E86><U+5220><U+9664><U+4E0B><U+5212><U+7EBF>,<U+5FD8><U+4E86><U+5728><U+53C2><U+6570><U+4E4B><U+95F4><U+5305><U+542B><U+9017><U+53F7>,<U+6216><U+8005><U+662F><U+5FD8><U+4E86><U+7528><code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>,<code>}<\\/code><U+6765><U+5C01><U+95ED><code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code><U+3002> or <code>{<\\/code><U+3002>\\n\",\"unparsablequotes\":\"<p><U+60A8><U+7684>R<U+4EE3><U+7801><U+4E2D><U+4F3C><U+4E4E><U+542B><U+6709><U+7279><U+6B8A><U+683C><U+5F0F><U+7684><U+5F15><U+53F7>,<U+6216><U+8005><U+5F2F><U+5F15><U+53F7>(<code>{{character}}<\\/code>) <U+5728><U+5B57><U+7B26><U+4E32><U+524D><U+540E>,<U+5728>R<U+4E2D><U+5B57><U+7B26><U+4E32><U+5E94><U+8BE5><U+88AB><U+76F4><U+5F15><U+53F7>(<code>&quot;<\\/code> <U+6216><U+8005> <code>'<\\/code>)<U+5305><U+88F9><U+3002><\\/p> {{code}} <p><U+522B><U+62C5><U+5FC3>,<U+8BE5><U+9519><U+8BEF><U+7ECF><U+5E38><U+5728><U+590D><U+5236><U+7C98><U+8D34><U+5305><U+542B><U+683C><U+5F0F><U+7684><U+4EE3><U+7801><U+65F6><U+9047><U+5230>, <U+60A8><U+53EF><U+4EE5><U+5C1D><U+8BD5><U+5C06><U+8BE5><U+884C><U+4E2D><U+7684><U+4EE3><U+7801><U+66FF><U+6362><U+4E3A><U+4EE5><U+4E0B><U+4EE3><U+7801>,<U+4E5F><U+8BB8><U+8FD8><U+6709><U+5176><U+4ED6><U+5730><U+65B9><U+9700><U+8981><U+4FEE><U+6539><U+3002><\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p><U+60A8><U+7684><U+4EE3><U+7801><U+4E2D><U+4F3C><U+4E4E><U+5305><U+542B><U+6709><U+5F02><U+5E38><U+5B57><U+7B26>(<code>{{character}}<\\/code>),<U+5BFC><U+81F4><U+4EE3><U+7801><U+65E0><U+6548><U+3002><\\/p> {{code}} <p><U+6709><U+65F6><U+5019><U+4F60><U+7684><U+4EE3><U+7801><U+53EF><U+80FD><U+542B><U+6709><U+770B><U+4F3C><U+6B63><U+5E38><U+5B57><U+7B26><U+7684><U+7279><U+6B8A><U+5B57><U+7B26>,<U+7279><U+522B><U+662F><U+5F53><U+4F60><U+590D><U+5236><U+7C98><U+8D34><U+5176><U+4ED6><U+6765><U+6E90><U+4EE3><U+7801><U+7684><U+65F6><U+5019><U+3002> <U+8BF7><U+8BD5><U+7740><U+5220><U+9664><U+8FD9><U+4E9B><U+7279><U+6B8A><U+5B57><U+7B26>,<U+91CD><U+65B0><U+8F93><U+5165><\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p><U+60A8><U+7684><U+4EE3><U+7801><U+4E2D><U+4F3C><U+4E4E><U+5305><U+542B><U+6709><U+5F02><U+5E38><U+5B57><U+7B26>(<code>{{character}}<\\/code>),<U+5BFC><U+81F4><U+4EE3><U+7801><U+65E0><U+6548><U+3002><\\/p> {{code}} <p><U+6709><U+65F6><U+5019><U+4F60><U+7684><U+4EE3><U+7801><U+53EF><U+80FD><U+542B><U+6709><U+770B><U+4F3C><U+6B63><U+5E38><U+5B57><U+7B26><U+7684><U+7279><U+6B8A><U+5B57><U+7B26>,<U+7279><U+522B><U+662F><U+5F53><U+4F60><U+590D><U+5236><U+7C98><U+8D34><U+5176><U+4ED6><U+6765><U+6E90><U+4EE3><U+7801><U+7684><U+65F6><U+5019><U+3002> <U+8BF7><U+8BD5><U+7740><U+5220><U+9664><U+8FD9><U+4E9B><U+7279><U+6B8A><U+5B57><U+7B26>,<U+91CD><U+65B0><U+8F93><U+5165><\\/p>\\n\",\"and\":\"<U+4E14>\",\"or\":\"<U+6216>\",\"listcomma\":\",\",\"oxfordcomma\":\",\"}}},\"pl\":{\"translation\":{\"button\":{\"runcode\":\"Uruchom kod\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Podpowiedz\",\"hint_plural\":\"Podpowiedzi\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Nastepna podpowiedz\",\"hintprev\":\"Poprzednia podpowiedz\",\"solution\":\"Rozwiazanie\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Kopiuj do schowka\",\"startover\":\"Zacznij od poczatku\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Kontynuuj\",\"submitanswer\":\"Wyslij\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Poprzednia sekcja\",\"nexttopic\":\"Nastepna sekcja\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Spróbuj ponownie\"},\"text\":{\"startover\":\"Zacznij od poczatku\",\"areyousure\":\"Czy na pewno chcesz zaczac od poczatku? (caly postep w zadaniu zostanie utracony)\",\"youmustcomplete\":\"Musisz ukonczyc\",\"exercise\":\"cwiczenie\",\"exercise_plural\":\"cwiczenia\",\"inthissection\":\"w tej sekcji przed kontynuowaniem\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"luka\",\"blank_plural\":\"luk(i)\",\"exercisecontainsblank\":\"To cwiczenie zawiera {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Prosze uzupelnic {{blank}} prawidlowym kodem.\",\"unparsable\":\"Wyglada na to, ze moze to nie byc prawidlowy kod R. R nie jest w stanie przetworzyc Twojego tekstu na polecenie. Mogles(-as) zapomniec wypelnic luki, usunac podkreslnik, umiescic przecinka miedzy argumentami, lub zamknac znak <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> lub <code>{<\\/code> odpowiadajacym <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> lub <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>Wyglada na to, ze Twój kod zawiera szczególnie sformatowane cudzyslowy lub cudzyslowy typograficzne (<code>{{character}}<\\/code>) przy ciagach znaków, co sprawia, ze kod jest niepoprawny. R wymaga cudzyslowów prostych (<code>&quot;<\\/code> albo <code>'<\\/code>).<\\/p> {{code}} <p>Nie martw sie, to powszechne zródlo bledów, gdy kopiuje sie kod z innego programu, który sam formatuje teskt. Mozesz spróbowac zastapic swój kod nastepujacym kodem. Moga byc tez inne miejsca, które wymagaja poprawienia.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>Wyglada na to, ze Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, ze kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod moze zawierac znak specjalny, który wyglada jak zwykly znak, zwlaszcza jesli kopiujesz kod z innego programu. Spróbuj usunac znak specjalny i wpisac do ponownie recznie.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>Wyglada na to, ze Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, ze kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod moze zawierac znak specjalny, który wyglada jak zwykly znak, zwlaszcza jesli kopiujesz kod z innego programu. Mozesz spróbowac zastapic swój kod nastepujacym kodem. Moga byc tez inne miejsca, które wymagaja poprawienia.<\\/p> {{suggestion}}\\n\",\"and\":\"i\",\"or\":\"lub\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}}}}<\/script>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.10.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.15"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["5.5.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.4.14"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["2.0.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.2"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122]}},"value":[{"type":"character","attributes":{},"value":["assertthat","backports","base","broom","bslib","cachem","cellranger","checkmate","cli","codetools","colorspace","compiler","corrplot","crayon","curl","data.table","datasets","DBI","dbplyr","digest","dplyr","dslabs","ellipsis","evaluate","fansi","farver","fastmap","forcats","fs","gargle","generics","ggplot2","ggwordcloud","glue","googledrive","googlesheets4","gradethis","graphics","grDevices","grid","gtable","haven","highr","hms","htmltools","htmlwidgets","httpuv","httr","janeaustenr","jquerylib","jsonlite","kableExtra","knitr","labeling","later","lattice","learnr","lexicon","lifecycle","lubridate","magrittr","markdown","Matrix","methods","mime","mnormt","modelr","munsell","nlme","parallel","pillar","pkgconfig","plyr","png","promises","psych","purrr","qdapRegex","R6","RColorBrewer","Rcpp","readr","readxl","reprex","reshape2","rlang","rmarkdown","rprojroot","rstudioapi","rvest","sass","scales","sentimentr","shiny","SnowballC","stats","stringi","stringr","svglite","systemfonts","syuzhet","textclean","textdata","tibble","tidyr","tidyselect","tidytext","tidyverse","tokenizers","tools","tzdb","utf8","utils","vctrs","viridisLite","webshot","withr","wordcloud","xfun","xml2","xtable","yaml"]},{"type":"character","attributes":{},"value":["0.2.1","1.4.1","4.1.2","1.0.0","0.4.0","1.0.6","1.1.0","2.1.0","3.3.0","0.2-18","2.0-3","4.1.2","0.92","1.5.1","4.3.2","1.14.2","4.1.2","1.1.3","2.2.1","0.6.29","1.0.9","0.7.4","0.3.2","0.16","1.0.3","2.1.1","1.1.0","0.5.2","1.5.2","1.2.0.9002","0.1.3","3.3.6","0.5.0","1.6.2","2.0.0","1.0.1.9000","0.2.3.9001","4.1.2","4.1.2","4.1.2","0.3.0","2.5.0","0.9","1.1.2","0.5.2","1.5.4","1.6.5","1.4.4","0.1.5","0.1.4","1.8.0","1.3.4","1.39","0.4.2","1.3.0","0.20-45","0.10.2","1.2.1","1.0.1","1.8.0","2.0.3","1.1","1.4-1","4.1.2","0.12","2.1.0","0.1.9","0.5.0","3.1-157","4.1.2","1.8.1","2.0.3","1.8.7","0.1-7","1.2.0.1","2.2.5","0.3.4","0.7.5","2.5.1","1.1-3","1.0.8.3","2.1.2","1.4.0","2.0.2","1.4.4","1.0.2","2.15","2.0.3","0.13","1.0.3","0.4.2","1.2.1","2.9.0","1.7.1","0.7.0","4.1.2","1.7.6","1.4.1.9000","2.1.0","1.0.4","1.0.6","0.9.3","0.4.2","3.1.7","1.2.0","1.1.2","0.3.3","1.3.2","0.2.1","4.1.2","0.3.0","1.2.2","4.1.2","0.4.1","0.4.0","0.5.3","2.5.0","2.6","0.31","1.3.3","1.8-4","2.3.5"]}]}]}
</script>
<!--/html_preserve-->
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">Match the code
snippet to questions on data!</h2>
<h4 class="author"><em>Simon Knight, <a
href="mailto:sjgknight@gmail.com" class="email">sjgknight@gmail.com</a>,
modified by Shibani Antonette, <a
href="mailto:antonette.shibani@gmail.com"
class="email">antonette.shibani@gmail.com</a>, and converted to a learnr
exercise in 2021 by sjgk</em></h4>
<h4 class="date"><em>2022-08-23</em></h4>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->



<!-- Build Tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
