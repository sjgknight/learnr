---
title: "Match the code snippet to questions on data!"
author: "Simon Knight, sjgknight@gmail.com, modified by Shibani Antonette, antonette.shibani@gmail.com, and converted to a learnr exercise in 2021 by sjgk"
output: learnr::tutorial
runtime: shiny_prerendered
description: "Welcome to this learnr tutorial!"
---

# Match the code to the question

In this notebook, we've got a set of questions. 

**Your challenge is to match the question, to the appropriate code chunk(s).  For charts you _don't_ use, can you explain why not/what's wrong with them?** 

Try and work out what the code chunk will output before you run it.

The code snippets are designed so you could copy them into your own work to do  analyses (if you wanted to), and to demonstrate useful functions. 

## Preliminaries
Load packages.  If you don't have them installed already, you should uncomment (delete the #) the first line in the following code block (starting 'install.packages')

Once you've done that, you can test the file by using the 'knit' button (in RStudio).

Read more about R markdown and 'kniting' (rendering) documents https://rmarkdown.rstudio.com/authoring_quick_tour.html#overview 

To read documentation and view examples of usage, type ?function_name in console (E.g. ?hist) or search from the help bar in RStudio.

### Load libraries and data
First, we'll load the required packages, they come with a bunch of built in data, and we're going to use that here.

```{r setup, echo=TRUE}
tutorial_options(exercise.timelimit = 25) #the default is 30, I'm including this here as a reference. You can also set this per exercise in the chunk with exercise.timelimit=10.  This places a constraint on running arbitrary code.
#It would be sensible to also include RAppArmor

knitr::opts_chunk$set(warning = FALSE)
#install.packages(c("psych","ggplot2","doBy","reshape2","knitr","lattice"))
  sh <- suppressPackageStartupMessages #To get rid os warning and other messages while loading the libraries
  sh(library(ggplot2))  #for graphs and plots
  sh(library(psych))    #for statistical measures and testing
  #sh(library(doBy))     #for group by analysis dplyr covers this
  #sh(library(reshape2)) #for data wrangling
  sh(library(knitr))    #for rendering markdown
  #sh(library(lattice))  #just to illustrate another histogram function 
  library(learnr)
  library(dslabs)
  library(shiny) #shouldn't be necessary but...
 # install.packages("remotes")
  #remotes::install_github("rstudio-education/gradethis")
  library(gradethis)
  gradethis_setup()
  library(textdata)
  library(wordcloud) #ggwordcloud could also be used to create comparison.cloud but for now I'll keep 
  library(ggwordcloud) #This library is interesting, it does the same things as wordcloud + wordcloud2 combined, and is in the ggplot2 family which means we can do all those things too
  #library(wordcloud2) #This may not work well when knitted
  library(kableExtra)
  #library(RSentiment) #for ease, takes whole sentences and assigns scores in various ways (while tidytext approaches use words) Described e.g. https://www.r-bloggers.com/2017/03/rsentiment/ Imports OpenNLP and NLP in addition to ^. We'd use function calculate_score 
  library(sentimentr) #more complete than RSentiment, many examples. Compares a range of approaches https://cran.r-project.org/web/packages/sentimentr/readme/README.html  Also has a nice function plot.sentiment_by which gives a ggplot object
  #this is great! https://github.com/trinker/sentimentr#examples
  library(tidyverse)
  library(tidytext)
  library(corrplot)
#detach(package:plyr)
  
#library(rsconnect)
#deployApp(appName = "Snippet_matchR)
#################################################################
#############LOAD DATA HERE######################################
#################################################################
#trump_tweets <- data("trump_tweets")
data("trump_tweets")
##############AND we're going to do some tidying up #############

links <- "https://t.co/[A-Za-z\\d]+|&amp;" #regex to get rid of picture links
tweet_words <- trump_tweets %>% 
  mutate(text = str_replace_all(text, links, ""))  %>%
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% stop_words$word &
           !str_detect(word, "^\\d+$")) %>%
  mutate(word = str_replace(word, "^'", ""))

##############And add sentiment analysis columns for later #########
bing <- get_sentiments("bing")
afinn <- get_sentiments("afinn")

#loughran <- get_sentiments("loughran") %>% count(sentiment)
#get_sentiments("nrc") %>% count(sentiment) 

nrc <- get_sentiments("nrc") %>%
  select(word, sentiment)

#Find the sentiment for each word, then count each sentiment for each tweet (using id_str as index), add these as columns using pivot_wider, and subtract from each other to give an overall score.  This isn't really correct, the words should be weighted by n of words, to give a score 0-1, or -1-+1 but it's fine for now.

trump_tweets %<>% 
  dplyr::mutate(sent_split = get_sentences(text)) %>%
  dplyr::mutate(sentiment_by(sent_split)) %>%
  dplyr::mutate(polarity = ifelse(ave_sentiment < 0.2, "Negative",
                           ifelse(ave_sentiment > 0.2, "Positive","Neutral")))


tt_senti2 <- tweet_words %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(id_str) %>%
  dplyr::summarise(sentiment_afinn = mean(value)) 

#mode <- function(codes){which.max(tabulate(codes))}
mode <- function(x) { names(which.max(table(x))) } #it's treated as factor below

tt_senti3 <- tweet_words %>%
  inner_join(get_sentiments("nrc")) %>%
  group_by(id_str) %>%
  dplyr::summarise(sentiment_nrc = mode(sentiment))
                
#join the sentiment to the original twitter data
#trump_tweets <- left_join(trump_tweets, tt_senti, by = c("id_str" = "index")) 
trump_tweets <- left_join(trump_tweets, tt_senti2, by = "id_str") 
trump_tweets <- left_join(trump_tweets, tt_senti3, by = "id_str") 

rm(tt_senti2,tt_senti3)

#table(tweet_words %>% inner_join(get_sentiments("nrc")) %>% select(sentiment)) 
#afinn is also pretty cool

```

```{r for_instructors, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#See file 'mapping matchr.docx' in folder for instructor explanation of this exercise
```


```{r dropped_code, eval=FALSE, include=FALSE}
#Some useful things from tidytext for later

#Common words
tweet_words %>% 
  count(word) %>%
  top_n(10, n) %>%
  mutate(word = reorder(word, n)) %>%
  arrange(desc(n))

#Let's look at common sentiments
tweet_words %>% inner_join(nrc, by = "word") %>% 
  select(source, word, sentiment) %>% 
  sample_n(5)

#Do some stuff by totals
sentiment_counts <- tweet_words %>%
  left_join(nrc, by = "word") %>%
  count(source, sentiment) %>%
  pivot_wider(names_from = "source", values_from = "n") %>%
  mutate(sentiment = replace_na(sentiment, replace = "none"))
sentiment_counts
sentiment_counts %>%
  mutate(Android = Android / (sum(Android) - Android) , 
         iPhone = iPhone / (sum(iPhone) - iPhone), 
         or = Android/iPhone) %>%
  arrange(desc(or))


##########################################
#And a play with labelling outliers (and using a log scale)

#There retweet data has a long tail, and so we're going to explicitly label our outliers because it'll help in a moment. 
trump_tweets %<>%
  group_by(source) %>%
  mutate(outlier.h = retweet_count > quantile(retweet_count, .75) + 1.50*IQR(retweet_count), 
         outlier.l = retweet_count < quantile(retweet_count, .25) - 1.50*IQR(retweet_count)) %>%
  ungroup

trump_tweets %>%
  filter(source %in% c("Twitter for Android","Twitter for iPhone")) %>% #filter to the two biggest sources
  #filter(quantile(retweet_count, 0.55)<retweet_count) 
  ggplot(aes(x = factor(source), y = log(retweet_count + 1))) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.
  geom_boxplot(outlier.shape = NA) + # Take outliers out, we're going to add them in with the code below
  geom_jitter(data = filter(trump_tweets, source %in% c("Twitter for Android","Twitter for iPhone") &
                            outlier.h ==T | outlier.l == T), color = "red", width = .2) + #outlier adding
  stat_summary(
    aes(label = round(stat(exp(y)), 1)),
    geom = "label_repel", 
    fun.y = function(y) { o <- boxplot.stats(y)$out; if(length(o) == 0) NA else o },
    position = position_nudge_repel()
  ) + 
    stat_summary(fun.y = mean, geom="point", shape=5, size=4) #show the mean

    #position=position_jitter()
    #hjust = -1

  #for the issue of dealing with splitting charts, see also
  #https://stackoverflow.com/questions/59140960/remove-outliers-and-reduce-ylim-appropriately-for-each-facet-in-ggplot2
  #and #https://stackoverflow.com/questions/7194688/using-ggplot2-can-i-insert-a-break-in-the-axis

```

# Task Explanation

We're going to look at the trump twitter data

I've put some questions below - what other questions can you think of from this dataset?

In some of the examples below, it's not about "right" and "wrong" answers, so much as "more" and "less" informative ones.  In other cases, there is a clear wrong answer :-). In both, we can discuss this! 

## Data Exploration
First, let's just look at the first 10 rows of the dataset to see what it includes.
You can change the below to tail(trump_tweets) or trump_tweets[1:100,], etc. 
Use the arrow in the top row to navigate through the columns.
```{r explore_datasets, exercise = TRUE}
#View the first 10 rows of the dataset
head(trump_tweets)
```

## Demonstrating a Table / Data Overview
Let's just take a look at some overall summary stats before we get into the visualisation. These are useful for a range of reasons, one of which is they can tell us about the shape of the data. Read about a part of that through measures of skew and kurtosis here: https://codeburst.io/2-important-statistics-terms-you-need-to-know-in-data-science-skewness-and-kurtosis-388fef94eeaa

```{r Summary of RT and Favs}
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% 
  select(c(favorite_count,retweet_count,source)) %>%
  psych::describeBy(favorite_count + retweet_count ~ source, data = ., mat = T) %>%
  kable(.,"html")

```
## Some demonstration

An example (a pretty ugly one, using base R) of a plot is in the code. We will see how this can be improved later. 
One easy fix we'll apply later is to rotate the x axis to show the number, not the notation. Unfortunately base R doesn't let us do that easily.
```{r basic histograms, echo=TRUE}
hist(trump_tweets$favorite_count)
```

We're also going to quickly demonstrate how part of this page works. The page is built on an r package called `learnr` which lets me insert exercises that you can run yourselves, and lets me check your answers! Cool right?

Here's a really basic example. In the box below, I want you to `assign` the value 2 to the variable x.
In r we assign by using the operator `<-`
This is preceded by the name of the variable, in this case `x`
And followed by the thing we're assigning, in this case `2`
So `y <- 3*3` assigns the value `9` to the variable `y`
Delete the code in the box to do this; the checker looks at your code rather than the output in this case.
```{r example, exercise = TRUE}
1+1

```

```{r example-solution}
x <- 2

```

```{r example-code-check}
grade_code()
```

We've made it easy below. You don't need to *write* your own code, just copy and paste our examples into the correct slot!

# The questions - copy the code chunk(s) that best addresses it under each question

## Q1. What is the relationship between retweets and likes?
Delete the wrong answers, leaving only 1 block (you can view the outputs for every block pre-rendered, or run this block)
```{r relationship, exercise = TRUE, exercise.lines=30 }
################### BLOCK 8 ########################
ggplot(trump_tweets, aes(x = retweet_count, y = favorite_count)) +
  geom_point(shape = 1) 
cor.test(trump_tweets$retweet_count,trump_tweets$favorite_count)
################### BLOCK 7 ########################
trump_tweets %>% 
  select(created_at,retweet_count,favorite_count) %>%
  pivot_longer(cols = c("retweet_count","favorite_count"), names_to = "variable", values_to = "count") %>%
     mutate(created_at=as.Date(created_at, format = "%Y-%m-%d")) %>%
  filter(created_at > "2015-01-01") %>%
  ggplot(aes(x=created_at, y=count, group=variable, colour=variable)) + 
  geom_line() +
  geom_point()
################### BLOCK 17 ########################
#We'll compare the bottom 25% of retweet counts to the rest by average favourites
ggplot(trump_tweets %>% mutate(retweeted = ifelse(retweet_count > quantile(retweet_count, .25), "Y", "N")), 
       aes(x = retweeted, y = favorite_count)) + 
  geom_bar(stat="summary", fun="mean", fill="steelblue", position = "dodge") + 
  theme_minimal() +
  stat_summary(geom = "errorbar", fun.data = "mean_se", position = "dodge")
```

```{r relationship-solution}
ggplot(trump_tweets, aes(x = retweet_count, y = favorite_count)) +
  geom_point(shape = 1) 
cor.test(trump_tweets$retweet_count,trump_tweets$favorite_count)
```

```{r relationship-code-check}
grade_code()
#block 8 - correct
#block 7 and 17
## #Is date an important variable in this analysis? Does the scaling of the data gives us the best available insight into relationships of paired values? 
#you might also look at those 4 v high values
# trump_tweets %>% 
#   slice_max(retweet_count, n = 4) %>%
#   select(text,created_at,retweet_count,favorite_count,source) #uses dplyr slice function, and selects the columns we're interested in
```


## Q2. What source has the highest sentiment?
For this one, we can see four tweets in the same range, what are the values and their content (the tweet text)?
```{r max, exercise = TRUE, exercise.lines=30 }
########################BLOCK 13 ############################
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone")) %>% #filter to the two biggest sources
  ggplot(aes(x = factor(source), y = ave_sentiment)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4)
################### 
trump_tweets %>% 
  filter(source == "Twitter for Android") %>%
  slice_max(ave_sentiment, n = 1) %>%
  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in
################### 
trump_tweets %>% 
  filter(source == "Twitter for iPhone") %>%
  slice_max(ave_sentiment, n = 1) %>%
  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in
################### BLOCK 2 ########################
ggplot(trump_tweets, 
       aes(x = source, y = ave_sentiment)) + 
  geom_bar(stat="summary", fun="mean", fill="steelblue", position = "dodge") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))
```

```{r max-solution}
#block 13
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone")) %>% #filter to the two biggest sources
  ggplot(aes(x = factor(source), y = ave_sentiment)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4)

trump_tweets %>% 
  filter(source == "Twitter for Android") %>%
  slice_max(ave_sentiment, n = 1) %>%
  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in

trump_tweets %>% 
  filter(source == "Twitter for iPhone") %>%
  slice_max(ave_sentiment, n = 1) %>%
  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in

```

```{r max-code-check}
grade_code()
#block 13
#Distractor is block 2
#For interest, you could also look at the lowest sentiment two
# trump_tweets %>% 
#   filter(source == "Twitter for Android") %>%
#   slice_min(ave_sentiment, n = 1) %>%
#   select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in
# 
# trump_tweets %>% 
#   filter(source == "Twitter for iPhone") %>%
#   slice_min(ave_sentiment, n = 1) %>%
#   select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in

```


## Q3. How do iphone and android compare in terms of number of words?
```{r summary1, exercise = TRUE, exercise.lines=30 }
################### BLOCK 5 ########################
ggplot(trump_tweets %>% filter(source %in% c("Twitter for Android","Twitter for iPhone")), 
       aes(x = source, y = word_count)) + 
  geom_bar(stat="identity", fill="steelblue") + 
  theme_minimal() +
  stat_summary(geom = "errorbar", fun.data = mean_se, position = "dodge")
################### BLOCK 6 ########################
#Second version - sometimes it's useful to think about what information is included in different representations
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  ggplot(aes(x = factor(source), y = word_count)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4)
############
kable(table(trump_tweets$source), output = "html")
############
ggplot(trump_tweets %>% filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")), 
       aes(x = word_count, fill = source)) + 
  geom_histogram(alpha = .5, position = 'identity',  
                 aes(y = ..density..*width), show.legend = FALSE) + 
  facet_grid (. ~ source) ##..density..*width shows the proportion effectively normalised by group (iphone and android).  #note use of 'density' because we have unequal  counts in each dataset, and this lets us understand the data as a proportion which accounts for the unequal samples Alpha is the transparency level.
################### BLOCK 1 ########################
#First version  - sometimes it's useful to think about what information is included in different representations
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  ggplot(aes(x = factor(source), y = word_count)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4) +
  geom_jitter()
############
kable(table(trump_tweets$source), output = "html")
############
ggplot(trump_tweets %>% 
         filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")), 
       aes(x = word_count, fill = source)) + 
  geom_histogram(alpha = .5, position = 'identity') + 
  facet_grid (. ~ source)     
```

```{r summary1-solution}
#Second version - sometimes it's useful to think about what information is included in different representations
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  ggplot(aes(x = factor(source), y = word_count)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4)

kable(table(trump_tweets$source), output = "html")

ggplot(trump_tweets %>% filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")), 
       aes(x = word_count, fill = source)) + 
  geom_histogram(alpha = .5, position = 'identity',  
                 aes(y = ..density..*width), show.legend = FALSE) + 
  facet_grid (. ~ source) ##..density..*width shows the proportion effectively normalised by group (iphone and android).  #note use of 'density' because we have unequal  counts in each dataset, and this lets us understand the data as a proportion which accounts for the unequal samples Alpha is the transparency level.

```

```{r summary1-code-check}
grade_code()

#block 6
#Distractors are block 5, and 1

#Note, showing the boxplots and the variation in the underlying data (and size) is the interest here. Jitter is often useful to show the actual underlying data, but here while it gives us insight into the smaller sample for tweetdeck there are too many points for it to be meaningful. 

```

## Q4. What NRC sentiments occur in each source ?
```{r props, exercise = TRUE, exercise.lines=30 }
################### BLOCK 9 ########################
# Scatterplot
trump_tweets %>%
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  mutate(senti_score = recode(sentiment_nrc, "negative" = 1, "anger" = 2, "disgust" = 3, "fear" = 4, "sadness" = 5, "surprise" = 6, "anticipation" = 7, "trust" = 8, "joy" = 9, "positive" = 10)) %>%
  ggplot(aes(x = senti_score, y = retweet_count)) +
  geom_point(shape = 1) +
  theme(axis.text.x = element_text(angle = 90)) + 
  facet_grid( ~ source)
#A correlation plot
trump_tweets %>%
    filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  mutate(senti_score = recode(sentiment_nrc, "negative" = 1, "anger" = 2, "disgust" = 3, "fear" = 4, "sadness" = 5, "surprise" = 6, "anticipation" = 7, "trust" = 8, "joy" = 9, "positive" = 10)) %>%
  select(retweet_count,senti_score) %>%
  na.omit() %>%
  cor() %>%
  corrplot()
################### BLOCK 11 ########################
# Stacked
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources)
  ggplot(aes(x=source, y=sentiment_nrc, fill=sentiment_nrc)) + 
    geom_bar(position="stack", stat="identity") +
    theme(axis.text.x = element_text(angle = 90))
################### BLOCK 12 ########################
# Stacked + percent - You might decide to remove tweetdeck too given it's a much smaller sample
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources)
  mutate(sentiment_nrc = factor(sentiment_nrc, levels=c("negative", "anger", "disgust", "fear", "sadness", "surprise",  "joy", "trust", "anticipation", "positive"))) %>%
ggplot(aes(x=source)) + 
    geom_bar(aes(fill=sentiment_nrc), position="fill") + 
  theme(axis.text.x = element_text(angle = 90)) + 
  scale_fill_manual(values = c("negative" = "#D55E00",
                               "anger" = "#CC79A7", 
                               "disgust" = "#E69F00", 
                               "fear" = "#F0E442", 
                               "sadness" = "red", 
                               "surprise" = "#999999",
                               "positive" = "#009E73", 
                               "anticipation" = "#56B4E9", 
                               "trust" = "green", 
                               "joy" = "#0072B2")
                    )
#attempt to use palettes that are visible to those with colour blindness. This palette should be ok.  Two biggest groups are ordered (by the mutate statement) so you can read from the bottom or the top. 
#trust, joy, anticipation, all intersect with positive 
#anger, disgust, fear, sadness all intersect with negative
#surprise is sometimes positive or negative with interactive https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm
```

```{r props-solution}
# Stacked + percent - You might decide to remove tweetdeck too given it's a much smaller sample
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources)
  mutate(sentiment_nrc = factor(sentiment_nrc, levels=c("negative", "anger", "disgust", "fear", "sadness", "surprise",  "joy", "trust", "anticipation", "positive"))) %>%
ggplot(aes(x=source)) + 
    geom_bar(aes(fill=sentiment_nrc), position="fill") + 
  theme(axis.text.x = element_text(angle = 90)) + 
  scale_fill_manual(values = c("negative" = "#D55E00",
                               "anger" = "#CC79A7", 
                               "disgust" = "#E69F00", 
                               "fear" = "#F0E442", 
                               "sadness" = "red", 
                               "surprise" = "#999999",
                               "positive" = "#009E73", 
                               "anticipation" = "#56B4E9", 
                               "trust" = "green", 
                               "joy" = "#0072B2")
                    )
```

```{r props-code-check}
grade_code()
#Block 12
#Distractors are blocks 9 and 11
#You might explore tests of association here. These allow us to investigate associations between categories (e.g., between tweet-source, and tweet-emotion incidence) 

```
## Q5. How are NRC sentiment, source, and RTs associated? 
```{r association, exercise = TRUE, exercise.lines=30 }
################### BLOCK 9 ########################
# Scatterplot
trump_tweets %>%
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  mutate(senti_score = recode(sentiment_nrc, "negative" = 1, "anger" = 2, "disgust" = 3, "fear" = 4, "sadness" = 5, "surprise" = 6, "anticipation" = 7, "trust" = 8, "joy" = 9, "positive" = 10)) %>%
  ggplot(aes(x = senti_score, y = retweet_count)) +
  geom_point(shape = 1) +
  theme(axis.text.x = element_text(angle = 90)) + 
  facet_grid( ~ source)
#A correlation plot
trump_tweets %>%
    filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  mutate(senti_score = recode(sentiment_nrc, "negative" = 1, "anger" = 2, "disgust" = 3, "fear" = 4, "sadness" = 5, "surprise" = 6, "anticipation" = 7, "trust" = 8, "joy" = 9, "positive" = 10)) %>%
  select(retweet_count,senti_score) %>%
  na.omit() %>%
  cor() %>%
  corrplot()
################### BLOCK 3 ########################
#Sometimes, the best way to address a question at this stage of the investigation is to break it down
#In this case, you've looked at sentiment by source, and you've looked at RTs by source.
#You could also look at RT by source, to investigate at a descriptive level
#(There's some sample code to do that in the feedback - it shows there's not much difference probably)
#But, at this stage you're getting into the need to do different kinds of analysis, but there's still more value to get from sticking to descriptives.
#To use this block, copy all this commented text
################### BLOCK 10 ########################
Boxplots by source and sentiment 
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  ggplot(aes(x = factor(sentiment_nrc), y = retweet_count)) + 
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4) +
  facet_grid(. ~ source) +
  theme(axis.text.x = element_text(angle = 90))
################### BLOCK 4 ########################
#You can have this one for free - heatmaps can be useful sometimes, but not like this. 
#trump_tweets %>% mutate(reply_to = ifelse(in_reply_to_user_id_str > 0, "Y", "N")) %>% 
trump_tweets %>% filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>%
  ggplot(aes(x = sentiment_nrc, source)) +
  geom_tile(aes(fill = retweet_count)) +
  theme(axis.text.x = element_text(angle = 90))
```

```{r association-solution}
#Sometimes, the best way to address a question at this stage of the investigation is to break it down
#In this case, you've looked at sentiment by source, and you've looked at RTs by source.
#You could also look at RT by source, to investigate at a descriptive level
#(There's some sample code to do that in the feedback - it shows there's not much difference probably)
#But, at this stage you're getting into the need to do different kinds of analysis, but there's still more value to get from sticking to descriptives.

#To use this block, copy all this commented text
```

```{r association-code-check}
grade_this_code(correct = "That's right!  There are ways you could explore this more, but crucially you should consider why you're conducting any particular analysis, and what your rationale is for treating the data the way you have. For example, does it really make sense to treat the emotion data as an interval level numeric variable for a correlation? (It seems to me to be at most ordinal, but likely nominal level data). You can see a couple of other insights here ")
#Block 3 (which is blank)
#Distractors are a bunch of boxplots in block 10, heatmap block 4, and scatterplot + corplot block 9
#on feedback note the below
#Boxplots by source and sentiment 

  trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources
  ggplot(aes(x = factor(sentiment_nrc), y = retweet_count)) + 
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4) +
  theme(axis.text.x = element_text(angle = 90))


trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% 
  select(c(favorite_count,retweet_count,sentiment_nrc)) %>%
  psych::describeBy(favorite_count + retweet_count ~ sentiment_nrc, data = ., mat = T) %>%
  kable(digits=2, "html")
```


## Q6. What kind of language do Trump's tweets use?
```{r words, exercise = TRUE, exercise.lines=30 }
################### BLOCK 15 ########################
wc <- tweet_words %>%
  anti_join(stop_words) %>%
  count(word) %>%
  slice_max(n, n = 500)
ggwordcloud2(wc, color = "random-dark", shape = "star")
################### BLOCK 16 ########################
wc <- tweet_words %>%
  anti_join(stop_words) %>%
  count(word) %>%
  slice_max(n, n = 500)
#wordcloud2(wc, color = "black", maxRotation = 0, minRotation = 0, shape = "diamond") #diamond is just a square
#wordcloud - different package - makes simple ones too, and has an inbuilt function for comparison.  We'll do that for 2 groups positive and negative words (but you could use more)
tweet_words %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  reshape2::acast(word ~ sentiment, value.var = "n", fill = 0) %>%  #ideally rewrite using spread from dplyr
  comparison.cloud(term.matrix = ., 
                   colors = c("grey20", "grey80"),
                   max.words = 100,
                   rot.per = 0)
```

```{r words-solution}
wc <- tweet_words %>%
  anti_join(stop_words) %>%
  count(word) %>%
  slice_max(n, n = 2000)

#wordcloud2(wc, color = "black", maxRotation = 0, minRotation = 0, shape = "diamond") #diamond is just a square

#wordcloud - different package - makes simple ones too, and has an inbuilt function for comparison.  We'll do that for 2 groups positive and negative words (but you could use more)
tweet_words %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  reshape2::acast(word ~ sentiment, value.var = "n", fill = 0) %>%  #ideally rewrite using spread from dplyr
  comparison.cloud(term.matrix = ., 
                   colors = c("grey20", "grey80"),
                   max.words = 100,
                   rot.per = 0)
```

```{r words-code-check}
grade_code()
#Correct is block 16, distractor 15

android_iphone_or <- tweet_words %>%
  count(word, source) %>%
  pivot_wider(names_from = "source", values_from = "n", values_fill = 0) %>%
  rename("Android"= "Twitter for Android", "iPhone" = "Twitter for iPhone") %>%
  select(c(word,Android,iPhone)) %>%
  mutate(or = (Android + 0.5) / (sum(Android) - Android + 0.5) / 
           ( (iPhone + 0.5) / (sum(iPhone) - iPhone + 0.5)))

#This shows frequently used words (>100 times) sorted by the odds ratio, which is a statistical representation that quantifies differences in how likely a thing (a word in this case) is likely to occur in different groups (iphone vs android, treatment vs placebo, etc.)
android_iphone_or %>% filter(Android+iPhone > 100) %>%
  arrange(desc(or))
  
android_iphone_or %>% filter(Android+iPhone > 100) %>%
  arrange(or)

```

# Code blocks
## Block 1
```{r ggplot summarystats}
#First version  - sometimes it's useful to think about what information is included in different representations
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  ggplot(aes(x = factor(source), y = word_count)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4) +
  geom_jitter()

kable(table(trump_tweets$source), output = "html")

ggplot(trump_tweets %>% 
         filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")), 
       aes(x = word_count, fill = source)) + 
  geom_histogram(alpha = .5, position = 'identity') + 
  facet_grid (. ~ source)                                              
```


## Block 2 
```{r bars 1}
ggplot(trump_tweets, 
       aes(x = source, y = ave_sentiment)) + 
  geom_bar(stat="summary", fun="mean", fill="steelblue", position = "dodge") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))
```

## Block 3
```{r blank}

#Sometimes, the best way to address a question at this stage of the investigation is to break it down
#In this case, you've looked at sentiment by source, and you've looked at RTs by source.
#You could also look at RT by source, to investigate at a descriptive level
#(There's some sample code to do that in the feedback - it shows there's not much difference probably)
#But, at this stage you're getting into the need to do different kinds of analysis, but there's still more value to get from sticking to descriptives.

#To use this block, copy all this commented text
```

## Block 4 - this one's a freebie, it doesn't answer any of the questions well 
```{r ggplot heatmap}
#You can have this one for free - heatmaps can be useful sometimes, but not like this. 

#trump_tweets %>% mutate(reply_to = ifelse(in_reply_to_user_id_str > 0, "Y", "N")) %>% 
  
trump_tweets %>% filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>%
  ggplot(aes(x = sentiment_nrc, source)) +
  geom_tile(aes(fill = retweet_count)) +
  theme(axis.text.x = element_text(angle = 90))

```

## Block 5
```{r ggplot barchart}

ggplot(trump_tweets %>% filter(source %in% c("Twitter for Android","Twitter for iPhone")), 
       aes(x = source, y = word_count)) + 
  geom_bar(stat="identity", fill="steelblue") + 
  theme_minimal() +
  stat_summary(geom = "errorbar", fun.data = mean_se, position = "dodge")

```

## Block 6
```{r ggplot summarystats-2}

#Second version - sometimes it's useful to think about what information is included in different representations
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  ggplot(aes(x = factor(source), y = word_count)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4)

kable(table(trump_tweets$source), output = "html")

ggplot(trump_tweets %>% filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")), 
       aes(x = word_count, fill = source)) + 
  geom_histogram(alpha = .5, position = 'identity',  
                 aes(y = ..density..*width), show.legend = FALSE) + 
  facet_grid (. ~ source) ##..density..*width shows the proportion effectively normalised by group (iphone and android).  #note use of 'density' because we have unequal  counts in each dataset, and this lets us understand the data as a proportion which accounts for the unequal samples Alpha is the transparency level.


```

## Block 7
```{r ggplot line example}

trump_tweets %>% 
  select(created_at,retweet_count,favorite_count) %>%
  pivot_longer(cols = c("retweet_count","favorite_count"), names_to = "variable", values_to = "count") %>%
     mutate(created_at=as.Date(created_at, format = "%Y-%m-%d")) %>%
  filter(created_at > "2015-01-01") %>%
  ggplot(aes(x=created_at, y=count, group=variable, colour=variable)) + 
  geom_line() +
  geom_point()

```

## Block 8
```{r ggplot scatterplot example}
ggplot(trump_tweets, aes(x = retweet_count, y = favorite_count)) +
  geom_point(shape = 1) 
cor.test(trump_tweets$retweet_count,trump_tweets$favorite_count)
```

## Block 9
```{r ggplot scatterplot2}
# Scatterplot
trump_tweets %>%
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  mutate(senti_score = recode(sentiment_nrc, "negative" = 1, "anger" = 2, "disgust" = 3, "fear" = 4, "sadness" = 5, "surprise" = 6, "anticipation" = 7, "trust" = 8, "joy" = 9, "positive" = 10)) %>%
  ggplot(aes(x = senti_score, y = retweet_count)) +
  geom_point(shape = 1) +
  theme(axis.text.x = element_text(angle = 90)) + 
  facet_grid( ~ source)


#A correlation plot
trump_tweets %>%
    filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  mutate(senti_score = recode(sentiment_nrc, "negative" = 1, "anger" = 2, "disgust" = 3, "fear" = 4, "sadness" = 5, "surprise" = 6, "anticipation" = 7, "trust" = 8, "joy" = 9, "positive" = 10)) %>%
  select(retweet_count,senti_score) %>%
  na.omit() %>%
  cor() %>%
  corrplot()

```

## Block 10
```{r ggplot side-by-side boxplot}
#Boxplots by source and sentiment 
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client")) %>% #filter to the  biggest sources
  ggplot(aes(x = factor(sentiment_nrc), y = retweet_count)) + 
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4) +
  facet_grid(. ~ source) +
  theme(axis.text.x = element_text(angle = 90))

```

## Block 11
```{r ggplot summarystats2}
# Stacked
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources)
  ggplot(aes(x=source, y=sentiment_nrc, fill=sentiment_nrc)) + 
    geom_bar(position="stack", stat="identity") +
    theme(axis.text.x = element_text(angle = 90))

```

## Block 12
```{r barchart}
# Stacked + percent - You might decide to remove tweetdeck too given it's a much smaller sample
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources)
  mutate(sentiment_nrc = factor(sentiment_nrc, levels=c("negative", "anger", "disgust", "fear", "sadness", "surprise",  "joy", "trust", "anticipation", "positive"))) %>%
ggplot(aes(x=source)) + 
    geom_bar(aes(fill=sentiment_nrc), position="fill") + 
  theme(axis.text.x = element_text(angle = 90)) + 
  scale_fill_manual(values = c("negative" = "#D55E00",
                               "anger" = "#CC79A7", 
                               "disgust" = "#E69F00", 
                               "fear" = "#F0E442", 
                               "sadness" = "red", 
                               "surprise" = "#999999",
                               "positive" = "#009E73", 
                               "anticipation" = "#56B4E9", 
                               "trust" = "green", 
                               "joy" = "#0072B2")
                    )
#attempt to use palettes that are visible to those with colour blindness. This palette should be ok.  Two biggest groups are ordered (by the mutate statement) so you can read from the bottom or the top. 

#trust, joy, anticipation, all intersect with positive 
#anger, disgust, fear, sadness all intersect with negative
#surprise is sometimes positive or negative with interactive https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm
```

## Block 13
```{r boxplot2}
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone")) %>% #filter to the two biggest sources
  ggplot(aes(x = factor(source), y = ave_sentiment)) +  #note, you'll often see , fill = factor(variable) here too, but unless it is adding additional information my view is colour is just visual noise, the axes already label the plots, adding colour doesn't add new information.
  geom_boxplot() +
  stat_summary(
    fun.y = mean, geom="point", shape=5, size=4)


trump_tweets %>% 
  filter(source == "Twitter for Android") %>%
  slice_max(ave_sentiment, n = 1) %>%
  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in

trump_tweets %>% 
  filter(source == "Twitter for iPhone") %>%
  slice_max(ave_sentiment, n = 1) %>%
  select(text,retweet_count,favorite_count,created_at,source,ave_sentiment) #uses dplyr slice function, and selects the columns we're interested in
    
```

## Block 14
```{r barchart2}
#separate bars
trump_tweets %>% 
  filter(source %in% c("Twitter for Android","Twitter for iPhone","TweetDeck","Twitter Web Client") & !is.na(sentiment_nrc)) %>% #filter to the  biggest sources) 
  ggplot(aes(source, fill=sentiment_nrc)) + 
    geom_bar(position = "dodge2") +
  theme(axis.text.x = element_text(angle = 90))
  
```

## Block 15
```{r wordcloud}
wc <- tweet_words %>%
  anti_join(stop_words) %>%
  count(word) %>%
  slice_max(n, n = 500)

ggwordcloud2(wc, color = "random-dark", shape = "star")
```

## Block 16
```{r wordcloud2}
wc <- tweet_words %>%
  anti_join(stop_words) %>%
  count(word) %>%
  slice_max(n, n = 500)

#wordcloud2(wc, color = "black", maxRotation = 0, minRotation = 0, shape = "diamond") #diamond is just a square

#wordcloud - different package - makes simple ones too, and has an inbuilt function for comparison.  We'll do that for 2 groups positive and negative words (but you could use more)
tweet_words %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  reshape2::acast(word ~ sentiment, value.var = "n", fill = 0) %>%  #ideally rewrite using spread from dplyr
  comparison.cloud(term.matrix = ., 
                   colors = c("grey20", "grey80"),
                   max.words = 100,
                   rot.per = 0)

```

## Block 17
```{r}
#We'll compare the bottom 25% of retweet counts to the rest by average favourites
ggplot(trump_tweets %>% mutate(retweeted = ifelse(retweet_count > quantile(retweet_count, .25), "Y", "N")), 
       aes(x = retweeted, y = favorite_count)) + 
  geom_bar(stat="summary", fun="mean", fill="steelblue", position = "dodge") + 
  theme_minimal() +
  stat_summary(geom = "errorbar", fun.data = "mean_se", position = "dodge")

```

